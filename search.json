[{"title":"RTCP协议详解","path":"/2025/06/27/RTCP协议详解/","content":"RTCP与RTP一样都是属于应用层的协议，其是RTP的控制协议。包括丢包控制；发送或者接受报告，其中包括上次报告到本次报告中间丢包率，延时等信息。 报文分类 SR和RR报文，分别用于发送和接收报文 SDES,用于描述音视频媒体源。 BYE报文用于说明哪些媒体源已经不可用，应该删除 APP报文，自定义报文 RTPFB,PSFB报文，未搞清楚什么作用。 需要注意这里的报文概念，与SDP，json、xml这类消息概念易混。 其中很重要的一个区别就是RTCP报文是二进制的。 RTCP协议头 重点是count字节，对于不同的报文类型，其含义是不同的。length字节表示整个的RTCP大小。 PT即payload Type","tags":["C++,WebRtc,RTCP"],"categories":["technology"]},{"title":"RTP协议详解","path":"/2025/06/27/RTP协议详解/","content":"首先要明确一点，RTP属于应用层协议，是架构在UDP之上的。在TCP协议中由于严格的重传机制，以及可靠协议特性，使其难以成为一个实时音视频领域协议。而UDP是一个不可靠协议，它并不严格要求包到达的顺序以及可靠到达，因此实时性最好。但是如何处理网络抖动以及丢包就成了难题，本片文章重点在于RTP是如何解决这些问题的。 UDP 数据报的结构 一个UDP数据报非常简单，它由两部分组成： **UDP头 (UDP Header)**：8个字节，包含源端口、目标端口、长度和校验和。 **UDP数据区 (UDP PayloadData)**：用来存放需要传输的数据。 [ UDP头 | UDP数据区 (用来放东西的地方) ] RTP 如何使用 UDP RTP协议首先构建好自己的数据包： **RTP头 (RTP Header)**：12字节或更多，包含序列号、时间戳等。 **RTP载荷 (RTP Payload)**：实际的音视频数据，比如一小段H.264编码的视频帧。 [ RTP头 | RTP载荷 (音视频数据) ] -- 这整个是一个完整的RTP包 然后，RTP把整个RTP包（RTP头 + RTP载荷）不加改变地，“塞”进了上面提到的 UDP数据区。 最终形成的数据包结构 所以，当数据包在网络中传输时，它的嵌套结构是这样的： +-------------------------------------------------------------------+| IP头 (网络层) || +---------------------------------------------------------------+ || | UDP头 (传输层) | || | +-----------------------------------------------------------+ | || | | 这整个部分是 UDP 的“数据区” / “Payload” | | || | | +----------------------+--------------------------------+ | | || | | | RTP头 (应用层) | RTP载荷 (真正的音视频数据) | | | || | | +----------------------+--------------------------------+ | | || | +-----------------------------------------------------------+ | || +---------------------------------------------------------------+ |+-------------------------------------------------------------------+ 丢包问题在RTP头中会对每个数据包进行编号，因此接收端很容易就可以判断哪些包丢失了，这个字段是sequence number 端口数据类型区分在实际设置中很有可能音频和视频在同一个端口进行输入。因此如何区分两种类型也是一个问题。PayloadType字段，通过该字段的设置可以将不同类型数据区分 exampleP8nbsp–nbsp96 Opus–11 另外，同一端口不仅可以传输不同类型的流，还可以传输哦同一类型，但是不同源的流，这就是上一篇提到的SSRC字段 RTP扩展头通过设置RTP头中的X字段为1可开启扩展头 其中profile是为了区分不同的配置，{0x10，0x0X}和{0xBE,0xDE}分别代表two-byte-header或者one-byte-header节来解析数据。length表示有几个header_extension。 在header-extension中，one-byte-header表示在he中的数据由一个字节的header和N字节的Body组成。而header中有4位的ID和4位的len。 RTP中的填充数据通过设置RTP头的P位可开启填充数据 当RTP中包含填充数据时数据包最后一个字节记录包中填充数据字节个数（包括自己），解包的时候从后往前去掉即可。","tags":["C++,WebRtc,RTP"],"categories":["technology"]},{"title":"WebRTC中的拥塞控制","path":"/2025/06/27/拥塞控制/","content":"在WebRTC中有多种控制算法，包括GCC,BBR,PCC。GCC又可以根据基于发送端或接收端，分为Transport-CC，Goog-REMB。 Goog-REMB 图中左侧为发送端，控制码流的发送；右侧为接收端，用于拥塞的评估和码流的计算 RemoteBitrate Estimator是接收端延迟拥塞控制算法的管理模块，从网络收发磨矿获取RTP包的传输信息用于拥塞评估。或者将内部评估出的下一时刻的发送码流大小，输出给网络收发模块，从而进行流控。另一方面，它要组织内部的Inter Arrival、OverUser Estimator等模块，根据当前观测到的延时差，和之前的评估指推断出下一时刻的网络拥塞情况 Inter Arrival首先将数据包按照帧分组，然后对相邻的两组数据包进行单项梯度计算。计算内容包括 每组数据包的发送时长 每组数据包的接收时长 两组数据包的大小差 OverUser Estimator利用IA计算出的结果，通过卡尔曼滤波估算出下一时刻发送队列的增长趋势。网络带宽是不断变化的，卡尔曼滤波器能够根据间接测量值，估算出真实结果。因此选用卡尔曼根据数据包时延来对带宽进行估计。 OverUse Detector用于检测当前网路中的拥塞情况，利用OE计算出的队列梯度延时以及自适应阈值进行比较。决定发包量的策略。 AIMD Rate Controller用于计算发送码流的大小，通过OD模块检测出当前网络状态，从而变更自己的状态，并计算出发送码流的大小 原理很简单，我们假设发送码流越大，状态越好。当OD检测出网络质量相比于现在呈上升，趋势，那么状态也上升。反之亦然 Transport CC在这个算法中，将拥塞算法从接收端移到了发送端，将卡尔曼换成了TrendLine GooCcNetworkController同样是对各个模块的控制。会调用子模块评估出下一时刻的网络拥塞状态和码流大小。并将评估出的码流交由Pacer和编码器模块进行码流控制 SendSideBandwidthEstimation比较基于接收端延时与发送端延时评估出的码流值，以及基于丢包，从中选择最小的码流值作为最终 DelayBaseBwe由多个模块构成，用于延时拥塞评估 trendline最小二乘法滤波器，拟合曲线。通过某一时刻线的斜率来判断此时线路是否拥塞，评估下一时刻码流大小 基于丢包的拥塞评估前面已经有两种方法用于拥塞评估，分别是卡尔曼和TrendLine，都是基于延时的。 还有一种基于丢包的，实际上就是通过设置丢包门限来评定此时的网络传输质量。 2%,网络质量很好，可以加大码率 2%x10%,说明网络与发送速率匹配 10%,需要降低码率至（1-0.5丢包率）当前码率 拥塞控制算法","tags":["C++,WebRtc,拥塞控制"],"categories":["technology"]},{"title":"提高实时通信中音视频服务质量的方法","path":"/2025/06/26/WebRTC中的SDP规范/","content":"SDP结构1 v=0 2 o=- 3409821183230872764 2 IN IP4 127.0.0.1 3 … 4 m=audio 9 UDP/TLS/RTP/SAVPF 111 103 104 … 5 … 6 a=rtpmap :111 opus /48000/2 7 a=rtpmap :103 ISAC /16000 8 a=rtpmap :104 ISAC /32000 标准SDP规范的规定较为简单，前三行为会话描述，对整个SDP有约束作用；第四行为媒体描述，各个媒体描述之间互不影响。在整个SDP中只能有一个会话描述，但是可以有多个媒体描述。 SDP的描述格式同样较为简单type=valueSDP中的信息webrtc为了实现实时的通信，对标准的SDP做了较大的调整。这里仅展示wR中的SDP内容 会话部分v:协议版本o:会话创建者s:会话名t:会话时长 (下面部分选自李超老师书籍WebRTC音视频技术) 媒体描述 媒体信息在SDP中最重要的内容就是媒体信息。我们看一下 SDP中媒体信息的具体格式，如下所示：m＝＜media＞＜port＞／＜numbers＞＜transport＞＜fmt＞．．． 其中，＜media＞表示媒体类型，可以是audio、video等。 ＜port＞／＜numbers＞表示该媒体使用的端口号。对于WebRTC而言，由于它不使用SDP中描述的网络信息，所以该端口号对它没任何意义。＜transport＞表示使用的传输协议，可以是UDP、TCP等。 ＜fmt＞表示媒体数据类型，一般为PayloadType列表，其具体含义需要使用＂a＝rtpmap：＂属性做进一步阐述。 我们来看一个具体的例子，如代码7．2所示。从代码中可以看到， media的值为audio，表示该媒体的类型为音频；port为9，可以直接忽略，因为WebRTC不使用标准SDP中的网络信息，所以这里的端口也就失去了意义；transport为UDP／TLS／RTP／SAVFP，表示底层使用了哪些传输协议；fmtlist的值为一串从111到126的数字，每个数字代表一个PayloadType，不同的PayloadType表示媒体数据使用了不同的编解码器或编解码器参数。 上面提到的UDP／TLS／RTP／SAVFP，其含义为：传输时底层使用 UDP；在UDP之上使用了DTLS协议来交换证书；证书交换好后，媒体数据由RTP进行传输（RTP运行在UDP之上），保证传输的可靠性；媒体数据（音视频数据）的安全性是由SRTP负责的，即对RTP包中的Body部分进行加密。此外，传输时还使用RTCP的feekback机制对传输信息进行实时反馈（SAVPF），以便进行拥塞控制。代码7．2 媒体信息 1 ...2 m=audio 9 UDP/TLS/RTP/SAVPF 111 103 104 9 0 8 106 105 13110 112 113 1263 ... 通过上面的介绍，我们已经清楚了SDP中的媒体信息是用来做什么的。不过媒体信息不只有上面的这些内容，它还有很多＂$a$＂的属性用来对前面的信息做进一步解释，如每个PayloadType的详细参数就是由它们说明的。音频媒体的描述前面已经介绍过了，但还有很多细节没有介绍。这些细节是无法通过一条＂ $\\mathrm{m}$＂行就能够描述清楚的，必须通过 ＂$ar t p m a p$＂对其做进一步解释才行。如代码7．3所示，在这段代码中，使用大量的＂ $\\mathrm{a}\\mathrm{rtpmap”}$ 属性对＂ $\\mathrm{m}$＂行做进一步阐释。 代码7．3 音频媒体示例 m = audio 9 UDP/TLS/RTP/SAVPF 111 103 104 9 ......a=rtpmap :111 opus /48000/2a=rtcp -fb:111 transport -cca=fmtp :111 minptime =10; useinbandfec =1a=rtpmap :103 ISAC /16000a=rtpmap :104 ISAC /32000a=rtpmap :9 G722 /8000... 这段代码中的第 1 行代码是对音频媒体的描述；第 $3 、 6 、 7 、 8$ 行代码使用＂a＝rtpmap＂解释了PayloadType使用的编解码器及其参数是什么；第 5 行代码＂$af m t p$＂属性指定了PayloadType的数据格式，即音频帧最小 10 ms —帧，使用带内FEC。 在WebRTC的SDP中，＂a＝rtpmap＂＂a＝fmtp＂属性随处可见。无论是音频媒体中，还是视频媒体中，都使用它们对媒体做进一步的解释。 (1) ＂a＝rtpmap＂属性 rtpmap（rtp map），通过字面含义可以知道它是一张 PayloadType与编码器的映射表，每个PayloadType都对应一个编码器。其格式定义在RFC4566中，如下所示：a＝rtpmap：＜payload type＞＜encoding name＞／＜clock rate＞［／＜encodingparameters＞］ 通过上面rtpmap的格式，可以很容易理解代码7．3中第3行代码的含义：Payload Type值为 111 的编码器是Opus，其时钟频率（采样率）为48000，音频通道数为2。同理，PayloadType值为103的编码器是ISAC，采样率为 16000 ；PayloadType值为 104 的编码器也是 ISAC，只不过其采样率变成了 32000 ；PayloadType值为 9 的编码器是G722，采样率是 $8000 . . . . .$. （2）＂ $\\mathrm{a}\\mathrm{fmtp}$＂属性fmtp（format parameters）用于指定媒体数据格式。 ＂$af m t p$＂属性的格式与rtpmap一样也是定义在RFC4566的第6节中，如下所示：a＝fmtp：＜format＞＜format specific parameters＞ 现在再来看一下代码7．3中的第5行代码，它描述了PayloadType值为 111 的数据（Opus数据）：以 10 ms 长的音频数据为一帧，并且数据是经FEC编码的。其中，＂usein bandfec $1$＂是WebRTC针对 Opus增加的fmtp值。如果你想了解这些细节，可以看一下相关的草案。 与音频媒体信息相比，视频媒体信息要复杂一些，在SDP中视频相关的描述如代码7．4所示。 代码7．4 视频媒体 m=video 9 UDP/TLS/RTP/SAVPF 96 ... 102 121 124 ...a=mid:1a=rtpmap :96 VP8 /90000...a=rtpmap :97 rtx /90000a=fmtp :97 apt =96...a=rtpmap :102 H264 /90000...a=fmtp :102 level -asymmetry -allowed =1; packetization -mode =1; profile -level -id =42001f13 a=rtpmap :121 rtx /9000014 a=fmtp :121 apt =10215 ...16 a=rtpmap :124 red /9000017 a=rtpmap :119 rtx /9000018 a=fmtp :119 apt =12419 ... 其中，第 1 行代码为视频的＂ $\\mathrm{m}$＂行，其与音频的＂ $\\mathrm{m}$＂行类似，区别在于两者的媒体类型不同：一个是＂video＂，另一个则是 ＂audio＂。此外，第1行中的PayloadType列表也发生了变化，这个很好理解，视频媒体使用的编码器本就与音频媒体使用的不同。第3行代码表明视频媒体的ID编号为1，而音频媒体的ID编号为0。如果有更多的媒体，编号会一直累加。第 $5 \\sim 18$ 行代码是对不同 PayloadType的解释，下面看一下它们是如何解释PayloadType的吧。 第 5 行代码，PT（PayloadType）值为 96 表示媒体数据使用的编码器是VP8，其时钟频率为 90000 。又因为其排在＂ $\\mathrm{m}$＂行PT列表的第一位，所以它还是视频的默认编码器。同理，代码第 10 行，PT值为102表示媒体数据使用的是H264编码器，时钟频率也是 90000 。 第 7 行代码，PT值为 97 表示的含义与之前 PT值为 96 的情况有所不同，rtx表示的不再是编码器，而是丢包重传。要想弄明白第 7 行代码的含义，必须与第 8 行代码结合着一起看。在第 8 行代码中， apt（associated payload type）的值为 96 ，说明 96 与 97 是关联在一起的，PT＝97是PT＝96的补充。因此第7行代码的含义是：当 WebRTC使用的媒体数据类型（PayloadType）为96时，如果出现丢包需要重传，重传数据包的PayloadType为97。同理，第13～14行代码指明121是PT＝102重传包的PayloadType。 第16～18行代码较为特殊，要想了解这三行代码的含义，你还需要了解一些额外知识：一是red，它是一种在WebRTC中使用的FEC算法，用于防止丢包；二是red编码流程，默认情况下WebRTC会将 VP8／H264等编码器编码后的数据再交由red模块编码，生成带一些冗余信息的数据包，这样当传输中某个包丢了，就可以通过其他包将其恢复回来，而不用重传丢失的包。了解了上面这些内容后，第 $20 \\sim 22$行代码的含义应该就清楚了，即PT值为 124 表示需要使用red对之前编码好的数据再进行 red 处理， 119 是 PT $124$ 重传数据包的 PayloadType。如果用Wireshark等抓包工具抓取WebRTC媒体数据包时会发现它们都是red包，而在red包里装的是VP8／H264编码的数据。 再看一下与 H 264 相关的 fmtp 内 容。第 12 行代码，level－ asymmetry－allowed $1$ 指明通信双方使用的 H264Level是否要保持一致：0，必须一致；1，可以不一致。packetization mode指明经 H264编码后的视频数据如何打包，其打包模式有三种：0，单包；1，非交错包；2，交错包。三种打包模式中，模式0和模式1用在低延时的实时通信领域。其中模式 0 的含义是每个包就是一帧视频数据；模式1的含义是可以将视频帧拆成多个顺序的RTP包发送，接收端收到数据包后，再按顺序将其还原。profile－level－id由三部分组成，即 profile＿idc、profile＿iop以及level＿idc，每个组成部分占8位，因此可以推测出profile＿idc $42$ 、profile＿iop $00$ 、level＿idc $1$ f。关于这几个值的具体含义，如果读者感兴趣，可以自行查看H264规范手册。 以上分析将SDP中视频媒体信息相关的内容及其含义讲解清楚了。音视频媒体信息是SDP中最为重要的内容，读者一定要牢牢掌握。 另外一个媒体描述是SSRC，它是媒体源的唯一标识。需要注意的是，虽然原则上要求每一路媒体流都只有一个唯一的SSRC来标识它。但是我们可以使用 a = ssrc -grou:FID XXXXX MMMMM 不同的ssrc标识符来区分真正的视频流，以及重传的视频流。 SDP的版本标准SDP-PlanB-UnifiedPlan PlanB和Unified的最大的区别是，前者只有两个媒体描述，而如果要穿上多路的音视频流，那么这个时候要使用SSRC来进行区分，而在后这中可以有多个媒体描述，因此对于多路视频的情况只需要拆分成多个媒体描述（“m ”）即可 RTP扩展头通过使用“aexemap”扩展头，在原有的UDP基础上完完成扩展，进行SDP传输 服务质量“artcp-fb”,需要注意的是，这个字段即可以表示RTCP中专门反馈消息的一类消息。二是设置终端支持哪些feedback消息，通过设置编码器，拥塞算法等参数，影响服务质量。","tags":["C++,WebRtc,音视频服务质量"],"categories":["technology"]},{"title":"提高实时通信中音视频服务质量的方法","path":"/2025/06/23/webrtc中的实时通信增强方法/","content":"实时通信与带宽大小网络质量息息相关，根据香农定理和奈奎斯特定理其实很容易知道，码率、延迟和服务质量本身就是相悖的。而再加上信号传输本身的带宽有限（排除WebRtc中使用的架构），更加难以达到一个均衡。 那么为了提高音视频服务质量又该如何下手呢。有以下五个方面，这篇文章主要记录每个方面的一些重要算法。 增加带宽 减少数据量 适当增加时延 提高网络质量 快速准确评估带宽 增加带宽首先应该提到的肯定不是WebRtc中的一些算法，而是譬如5G网络，星链，新型传输材料，波分复用，时分复用，频分复用，等等通信方向的知识。但这并不在笔者将要探讨的WebRtc框架体系之内。 在WR内，客户端方面主要使用了一种极妙的选路方案来提高整体通信的带宽，即TURN-STUN结构。 STUN-TURN架构减少数据量 压缩算法，通过更好的压缩算法可以实现更高的码率 SVC技术，将视频按照时间、空间、质量分成多层编码、，然后将他们装在同一路发送给服务端，服务端收到后再根据每个用户的带宽情况不同来选择不同的层下发。 simulcast，将视频编码分成多个不同分辨率的多路码流，然后上传至服务端，服务端在根据客户的不同情况来进行下发。 动态码率 甩帧，减少业务， 增加时延实际上增加时延是增加一个缓冲区，先把到来的数据方法队列中缓冲一下，这样的话就可以减少网络抖动造成的卡断、快播、吞音等现象。一般而言对于实时音视频延迟应该控制在500ms以内。 提高网络质量对于网络质量主要有三个影响因素 丢包，优质网络丢包率应该小于2%，对于WR丢包率应该限制在2%-10% 延迟，拥塞 抖动，抖动较小的情况下，可以通过循环队列将其消除，抖动过大就会将乱序包作为丢包处理。在WR中抖动时长不能超过10ms，超过10ms会被视为丢包 解决上面问题的方法： NACKRTX NACK是RTCP的一种消息类型，向接收端报告一段时间内有哪些包丢失了，RTX是指向发送端重新发送丢失包 前向纠错，使用异或方式进行发送，以便在丢包时可以通过这种机制恢复丢失的包 JitterBufer 用于防抖动， 可以将少量乱序包恢复成有序 NetEQ 用于音频的防抖动","tags":["C++,WebRtc,音视频服务质量"],"categories":["technology"]},{"title":"SIMPLEST_FFMPEG_PLAYER源码阅读","path":"/2025/06/10/SIMPLEST_FFMPEG_PLAYER源码阅读/","content":"对于FFmpeg的使用中，理解各个结构体的作用至关重要。 解协议（http,rtsp,rtmp,mms） AVIOContext，URLProtocol，URLContext主要存储视音频使用的协议的类型以及状态。URLProtocol存储输入视音频使用的封装格式。每种协议都对应一个URLProtocol结构。（注意：FFMPEG中文件也被当做一种协议“file”） AVIOContext是FFmpeg中用于执行输入输出操作的抽象层，提供协议层之上的抽象接口，它负责处理数据流的读写和定位，而不需要知道底层数据的来源，因此可以处理本地，网络，内存缓冲区多个流来源。这个结构体包含了读写缓冲区的指针，缓冲区的大小，当前读写位置，和读写位置的指针（这些具体的指针指向集体的协议实现）等 在古早版本的FFmpeg中UP用于定义和注册不同的底层协议（如file\\http\\rtp\\tcp\\udp等），每个这样的结构体中都包含了针对该协议的一组回调函数（如url_open\\url_read\\url_read\\url_write\\url_seek\\url_close等）。但是在现代的FFmpeg中这个东嗯那个已经更多的整合和抽象进入AC中了。 同样的在古早版本中，UC是UP的一个具体实例，用于存贮某个已经打开协议连接的上下文信息。但是在新版的FFmpeg中这个结构也已经被整合到了AC中 解封装（flv,avi,rmvb,mp4） AVFormatContext主要存储视音频封装格式中包含的信息；AVInputFormat存储输入视音频使用的封装格式。每种视音频封装格式都对应一个AVInputFormat 结构。 在阅读雷博士写的播放器的时候能够轻易地发现这个结构体是一个很重要的结构体，它不仅是用于解封装到解码中间，在其他地方也是可以看到的。但是在这个结构体中实际上并没有什么很复杂的信息。只有类似音视频流的个数，音视频流，时长，比特率之类的东西。以及显示音视频流（文件）的源信息 解码（h264,mpeg2,aac,mp3） 每个AVStream存储一个视频音频流的相关数据；每个AVStream对应一个AVCodecContext，存储该视频音频流使用解码方式的相关数据；每个AVCodecContext中对应一个AVCodec，包含该视频音频对应的解码器。每种解码器都对应一个AVCodec结构。AVStream1. 这个结构体可以理解成为媒体文件中的轨道信息。AVCodecContex1. 这个结构体在编码和解码中都有应用，用于存储编解码器的上下文实例2. 解码过程，用于存储和接收编码器配置，打开一个媒体文件时候FFmpeg会从文件头部解析出视频流的编码参数，包括像视频宽度高度，像素格式，时间基准，音视频采样率等。另外配置编码器选项，跳帧策略，线程数，错误隐藏策略，是否允许多线程解码。传递压缩数据和接收原始数据： 会把压缩后的 AVPacket （例如一个H.264 NALU）传递给 AVCodecContext 对应的解码器（通过 avcodec_send_packet）。解码器处理后，会从 AVCodecContext 对应的解码器中读取解码后的 AVFrame （例如YUV像素数据或PCM采样数据，通过 avcodec_receive_frame）。3. 编码过程。首先还是设置编码参数，包括输入原始视频的尺寸和格式，编码器的时间基准，B帧最大数量等。配置编码选项，例如一些预设和调优，编码速度，编码模式等。传递原始数据和接收压缩数据： 你会把原始的 AVFrame （例如YUV像素数据或PCM采样数据）传递给 AVCodecContext 对应的编码器（通过 avcodec_send_frame）。编码器处理后，你会从 AVCodecContext 对应的编码器中读取压缩后的 AVPacket （例如H.264 NALU或AAC帧，通过 avcodec_receive_packet）。4. 这个接口一般是应用程序和底层编解码算法之间的桥梁，FFmpeg由此提供了统一的接口来配置不同的编解码器。有关于其他参数的解析还是看一下雷博士的博客。AVCodec1. AVCodec代表了一个具体的已经注册的编码器算法，它是一个只读的结构体，包含着这个编码器本身的静态通用信息，和能力。以及只想内部实现函数的指针。一般通过avcodec_find_decoder或者avcodec_find_encoder来获取这样一个指针。可以理解这是一个解码算法所提供的指针。2. 要注意AC的存储是以一个全局的注册列表形式（可能是一个链表或是其他的数据结构）实现的。由于FFmpeg时支持多种音视频编解码的这些编解码器在编译时可以被静态链接，作为共享库进行动态加载，允许 FFmpeg 在运行时动态地查找和选择合适的编解码器。3. AVCodec 定义了编解码器的抽象接口（例如 decode, encode, init, close 等函数指针）。具体的编解码器实现（例如 libx264、libvpx、libfdk_aac 等第三方库或 FFmpeg 内部实现）则通过 AVCodec 结构体将自己注册到 FFmpeg 中。这种设计使得 FFmpeg 核心库无需知道所有编解码器的具体实现细节，只需通过统一的 AVCodec 接口来调用它们。 存数据 视频的话，每个结构一般是存一帧；音频可能有好几帧 解码前数据：AVPacket1. 这个结构体比较简单，都是一些时间戳，大小之类的数据，解码后数据：AVFrame 1. AF中包含了多个码流参数，其中又以data数组为核心，主要是存储原始数据。在data数组中对于packed和planar数据的存储格式是不一样的。 2. 在AVPictureType结构体中IBP较为常见，但是要注意S\\SI\\BI\\BP帧类型，S 帧是一种特殊的编码帧，它本身是帧间预测的（像 P 帧），但它的预测信息（运动矢量、残差）可以被后续的 I 帧或 P 帧作为参考。SI 帧是一种特殊的 I 帧。它所有的宏块都是帧内编码的（像 I 帧一样），所以它是一个独立的帧，不依赖其他帧进行预测。 它的主要作用也是提供随机访问点，但它通常是为了更快速、更鲁棒的切换而设计。与普通的 I 帧相比，SI 帧可能在编码方式或解码端处理上有一些特定优化，以确保在它这里可以立即开始一个新的解码序列。BI 帧是一种非常特殊的帧，它包含的宏块全部是帧内编码的（就像 I 帧），但它却像 B 帧一样，既可以被向前参考，也可以被向后参考。SP 帧是一种特殊的 P 帧。它的大部分宏块都是帧间预测的（像 P 帧），但它的预测信息（运动矢量、残差）可以被后续的 I 帧或 P 帧作为参考。 3. qscale_table，网上绝大部分关于这个结构体的论述都是搬得雷博士的，需要注意宏块在视频帧指的是一个矩形块，而QP值其实是QP_step的一个索引，规定了宏块的采样步数，这个索引表是可以被查到的。 4. 另外以及像运动矢量和运动估计参考帧都比较容易理解接下来是以雷博士做的SIMPLEST_FFMPEG_PLAYER为例（注意是第一版），在上面添加注释，详细分析每个语句的作用，以及视频播放器的工作流程。 /** **核心流程：****FFmpeg 部分：*** 初始化 FFmpeg 库。* 打开视频文件并查找视频流。* 查找并打开视频解码器。* 分配用于存储解码帧和转换后YUV帧的内存。* 初始化 SWS_Scaler (用于图像格式转换)。**SDL 部分：*** 初始化 SDL 库。* 创建 SDL 窗口、渲染器和纹理。**主循环：*** 从视频文件中读取数据包 (`AVPacket`)。* 将数据包发送给解码器 (`avcodec_decode_video2`)。* 如果解码器成功解码出图像 (`got_picture` 为真)，则：* 使用 SWS_Scaler 将解码后的帧转换为 YUV420P 格式。* （可选）将 YUV420P 数据写入文件。* 使用 SDL 更新纹理、清空渲染器、复制纹理到渲染器并呈现，从而显示视频帧。* 延时一小段时间以控制播放速度。* 刷新解码器（处理剩余的帧）。* 释放所有分配的资源并退出。**//** * 最简单的FFmpeg播放器 2 * Simplest FFmpeg Player 2 * * 作者：雷霄骅 Lei Xiaohua.注释作者：yahei * 版本2：使用SDL 2.0取代了版本1中的SDL 1.2。 * Version 2 use SDL 2.0 instead of SDL 1.2 in version 1. * * 本程序实现了一个视频文件的解码和显示（支持HEVC, H.264, MPEG2等）。 * 这是一个最简单的FFmpeg视频解码方法。 * 通过学习这个示例可以初步了解FFmpeg的解码流程。 * This software is a simplest video player based on FFmpeg. * Suitable for beginner of FFmpeg. * */#include cstddef#include stdio.h// 宏定义，确保stdint.h中的常量宏可用，例如UINT64_C#define __STDC_CONSTANT_MACROS// 根据操作系统类型包含不同的头文件路径#ifdef _WIN32// Windows 平台extern C // 声明为C风格链接，因为FFmpeg和SDL库是C语言编写的#include include/libavcodec/avcodec.h // 包含FFmpeg编解码器库头文件#include include/libavformat/avformat.h // 包含FFmpeg封装格式库头文件#include include/libswscale/swscale.h // 包含FFmpeg图像缩放/格式转换库头文件#include SDL2/SDL.h // 包含SDL2库头文件;#else// Linux 或其他类Unix平台#ifdef __cplusplus // 如果是C++编译器，使用extern Cextern C#endif#include libavcodec/avcodec.h#include libavformat/avformat.h#include libswscale/swscale.h#include SDL2/SDL.h#ifdef __cplusplus;#endif#endif// 宏定义：是否将YUV420P数据输出到文件// 如果定义为1，则会将解码并转换后的YUV420P数据写入output.yuv文件// 如果定义为0，则不写入文件#define OUTPUT_YUV420P 0int main(int argc, char* argv[]) // FFmpeg 相关的结构体指针 AVFormatContext *pFormatCtx; // 封装格式上下文，包含了文件的整体信息（如流的数量、时长等） int i, videoindex; // i用于循环，videoindex用于存储视频流的索引 AVCodecContext *pCodecCtx; // 编解码器上下文，包含了编解码器操作所需的所有参数（如宽度、高度、像素格式等） AVCodec *pCodec; // 编解码器，代表一个具体的编解码器（如H.264解码器） AVFrame *pFrame, *pFrameYUV; // pFrame用于存储解码前的数据包（原始数据），pFrameYUV用于存储解码后并转换为YUV420P格式的帧 uint8_t *out_buffer; // 用于存储转换后YUV420P数据的缓冲区 AVPacket *packet; // 数据包，存储从文件中读取的压缩数据（如H.265或H.264帧） int y_size; // Y分量的大小，用于计算YUV数据的总大小和写入YUV文件 int ret, got_picture; // ret用于接收函数返回值，got_picture指示是否解码出一张完整的图片 // SWS_Scaler 上下文，用于图像格式转换（例如从解码器的原生像素格式转换为YUV420P） struct SwsContext *img_convert_ctx; // 输入文件路径 char filepath[] = bigbuckbunny_480x272.h265; // 要播放的视频文件路径 // SDL 相关变量 int screen_w = 0, screen_h = 0; // 屏幕（窗口）的宽度和高度 SDL_Window *screen; // SDL 窗口对象 SDL_Renderer* sdlRenderer; // SDL 渲染器，用于在窗口上绘图 SDL_Texture* sdlTexture; // SDL 纹理，用于存储YUV数据并渲染到屏幕 SDL_Rect sdlRect; // SDL 矩形，定义纹理在窗口上的显示区域 FILE *fp_yuv; // 用于输出YUV文件时的文件指针 // FFmpeg 初始化 av_register_all(); // 注册所有可用的编解码器、复用器/解复用器等组件 avformat_network_init(); // 初始化网络模块，如果需要处理网络流（例如HTTP, RTSP等） pFormatCtx = avformat_alloc_context(); // 分配一个AVFormatContext结构体 // 打开输入流（文件或网络流） // avformat_open_input 负责打开媒体文件并读取其头部信息 if (avformat_open_input(pFormatCtx, filepath, NULL, NULL) != 0) printf(Couldnt open input stream. ); // 如果文件无法打开，打印错误信息 return -1; // 查找输入流信息 // avformat_find_stream_info 负责读取媒体文件的一部分，填充pFormatCtx中的流信息（nb_streams, streams等） if (avformat_find_stream_info(pFormatCtx, NULL) 0) printf(Couldnt find stream information. ); // 如果无法找到流信息，打印错误信息 return -1; // 找到视频流的索引 videoindex = -1; // 视频流索引初始化为-1（未找到） for (i = 0; i pFormatCtx-nb_streams; i++) // 遍历所有流 // 检查当前流的类型是否为视频流 if (pFormatCtx-streams[i]-codec-codec_type == AVMEDIA_TYPE_VIDEO) videoindex = i; // 找到视频流，记录其索引 break; // 退出循环 if (videoindex == -1) printf(Didnt find a video stream. ); // 如果没有找到视频流，打印错误信息 return -1; // 获取视频流的编解码器上下文 pCodecCtx = pFormatCtx-streams[videoindex]-codec; // 从视频流中获取其对应的AVCodecContext // 找到视频解码器 // avcodec_find_decoder 根据编解码器ID（pCodecCtx-codec_id）找到对应的解码器 pCodec = avcodec_find_decoder(pCodecCtx-codec_id); if (pCodec == NULL) printf(Codec not found. ); // 如果没有找到解码器，打印错误信息 return -1; // 打开解码器 // avcodec_open2 负责打开解码器，并为它分配必要的资源 if (avcodec_open2(pCodecCtx, pCodec, NULL) 0) printf(Could not open codec. ); // 如果无法打开解码器，打印错误信息 return -1; // FFmpeg 内存分配 pFrame = av_frame_alloc(); // 分配一个AVFrame结构体，用于存储解码后的原始帧数据 pFrameYUV = av_frame_alloc(); // 分配一个AVFrame结构体，用于存储转换为YUV420P格式后的帧数据 // 计算YUV420P格式的图像数据所需的大小，并分配缓冲区 out_buffer = (uint8_t *)av_malloc(avpicture_get_size(PIX_FMT_YUV420P, pCodecCtx-width, pCodecCtx-height)); // 将分配的缓冲区与pFrameYUV关联起来，avpicture_fill会设置pFrameYUV-data和pFrameYUV-linesize // 注意：在FFmpeg 4.0+版本中，PIX_FMT_YUV420P 已被 AV_PIX_FMT_YUV420P 取代 avpicture_fill((AVPicture *)pFrameYUV, out_buffer, PIX_FMT_YUV420P, pCodecCtx-width, pCodecCtx-height); packet = (AVPacket *)av_malloc(sizeof(AVPacket)); // 分配一个AVPacket结构体，用于存储从文件中读取的压缩数据包 // 输出文件信息 printf(--------------- File Information ---------------- ); av_dump_format(pFormatCtx, 0, filepath, 0); // 打印媒体文件的详细信息到控制台 printf(------------------------------------------------- ); // 初始化SWS_Scaler上下文，用于图像格式转换 // 从解码器输出的原始像素格式（pCodecCtx-pix_fmt）转换为YUV420P格式 // SWS_BICUBIC 是一个常用的缩放算法 img_convert_ctx = sws_getContext(pCodecCtx-width, pCodecCtx-height, pCodecCtx-pix_fmt, pCodecCtx-width, pCodecCtx-height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL);// 如果定义了OUTPUT_YUV420P宏，则打开YUV文件#if OUTPUT_YUV420P fp_yuv = fopen(output.yuv, wb+); // 以二进制写模式打开output.yuv文件#endif // SDL 初始化 // 初始化SDL视频、音频和定时器子系统 if (SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER)) printf(Could not initialize SDL - %s , SDL_GetError()); // 初始化失败，打印错误信息 return -1; screen_w = pCodecCtx-width; // 设置窗口宽度为视频宽度 screen_h = pCodecCtx-height; // 设置窗口高度为视频高度 // 创建SDL窗口 // SDL_WINDOWPOS_UNDEFINED 表示窗口位置由系统决定 // SDL_WINDOW_OPENGL 提示使用OpenGL渲染 screen = SDL_CreateWindow(Simplest ffmpeg players Window, SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED, screen_w, screen_h, SDL_WINDOW_OPENGL); if (!screen) printf(SDL: could not create window - exiting:%s , SDL_GetError()); // 窗口创建失败，打印错误信息 return -1; // 创建SDL渲染器 sdlRenderer = SDL_CreateRenderer(screen, -1, 0); // 创建SDL纹理 // SDL_PIXELFORMAT_IYUV 指定纹理的像素格式为IYUV (即YUV420P) // SDL_TEXTUREACCESS_STREAMING 表示纹理数据会频繁更新 sdlTexture = SDL_CreateTexture(sdlRenderer, SDL_PIXELFORMAT_IYUV, SDL_TEXTUREACCESS_STREAMING, pCodecCtx-width, pCodecCtx-height); // 设置SDL矩形，定义纹理在窗口上的显示区域 sdlRect.x = 0; sdlRect.y = 0; sdlRect.w = screen_w; sdlRect.h = screen_h; // SDL 初始化结束---------------------- // 主循环：读取、解码和显示视频帧 // av_read_frame 从输入流中读取一个AVPacket while (av_read_frame(pFormatCtx, packet) = 0) // 检查当前数据包是否属于视频流 if (packet-stream_index == videoindex) // 解码视频包 // avcodec_decode_video2 将压缩的AVPacket解码为AVFrame（原始帧） // got_picture 会在成功解码出完整图像时设置为非0 ret = avcodec_decode_video2(pCodecCtx, pFrame, got_picture, packet); if (ret 0) printf(Decode Error. ); // 解码错误 return -1; if (got_picture) // 如果成功解码出了一张完整的图片 // 图像格式转换 // sws_scale 将pFrame中的图像数据转换为YUV420P格式，并存储到pFrameYUV中 // pFrame-data 和 pFrame-linesize 包含原始帧的像素数据和行步长 // 0 表示从图像的第0行开始转换 // pCodecCtx-height 是图像的高度 // pFrameYUV-data 和 pFrameYUV-linesize 接收转换后的YUV数据和行步长 sws_scale(img_convert_ctx, (const uint8_t* const*)pFrame-data, pFrame-linesize, 0, pCodecCtx-height, pFrameYUV-data, pFrameYUV-linesize); // 如果定义了OUTPUT_YUV420P宏，则将YUV数据写入文件 #if OUTPUT_YUV420P y_size = pCodecCtx-width * pCodecCtx-height; // Y分量大小 fwrite(pFrameYUV-data[0], 1, y_size, fp_yuv); // 写入Y分量数据 fwrite(pFrameYUV-data[1], 1, y_size / 4, fp_yuv); // 写入U分量数据 (YUV420P中U/V是Y的1/4大小) fwrite(pFrameYUV-data[2], 1, y_size / 4, fp_yuv); // 写入V分量数据 #endif // SDL 渲染部分--------------------------- #if 0 // 这是一个旧的SDL_UpdateTexture用法，通常用于YUV数据的更新 SDL_UpdateTexture( sdlTexture, NULL, pFrameYUV-data[0], pFrameYUV-linesize[0] ); #else // 使用SDL_UpdateYUVTexture更新YUV纹理，更适合YUV420P三平面格式 SDL_UpdateYUVTexture(sdlTexture, sdlRect, pFrameYUV-data[0], pFrameYUV-linesize[0], // Y分量数据和行步长 pFrameYUV-data[1], pFrameYUV-linesize[1], // U分量数据和行步长 pFrameYUV-data[2], pFrameYUV-linesize[2]); // V分量数据和行步长 #endif SDL_RenderClear( sdlRenderer ); // 清空渲染器 // 将纹理复制到渲染器，NULL表示复制整个纹理到整个sdlRect定义的区域 SDL_RenderCopy( sdlRenderer, sdlTexture, NULL, sdlRect); SDL_RenderPresent( sdlRenderer ); // 更新屏幕显示 // SDL 渲染部分结束----------------------- // 延时以控制播放速度，这里简单固定延时40ms，约每秒25帧（1000ms / 40ms = 25帧） SDL_Delay(40); av_free_packet(packet); // 释放当前AVPacket的内存，准备读取下一个 // 刷新解码器（处理解码器中剩余的帧） // 在文件末尾，解码器内部可能还缓存了一些帧，需要通过不断调用解码函数直到没有更多帧输出 // 此时packet参数可以设置为NULL或一个空packet while (1) ret = avcodec_decode_video2(pCodecCtx, pFrame, got_picture, NULL); // 注意这里 packet 为 NULL if (ret 0) // 解码错误或没有更多数据 break; if (!got_picture) // 没有解码出新的图像 break; // 对剩余的帧进行格式转换和显示 sws_scale(img_convert_ctx, (const uint8_t* const*)pFrame-data, pFrame-linesize, 0, pCodecCtx-height, pFrameYUV-data, pFrameYUV-linesize); #if OUTPUT_YUV420P int y_size=pCodecCtx-width*pCodecCtx-height; // 重新计算y_size，虽然这里应该和之前一样 fwrite(pFrameYUV-data[0],1,y_size,fp_yuv); // Y fwrite(pFrameYUV-data[1],1,y_size/4,fp_yuv); // U fwrite(pFrameYUV-data[2],1,y_size/4,fp_yuv); // V #endif // SDL 显示剩余帧 SDL_UpdateTexture( sdlTexture, sdlRect, pFrameYUV-data[0], pFrameYUV-linesize[0] ); // 修正，这里应该用 SDL_UpdateYUVTexture SDL_RenderClear( sdlRenderer ); SDL_RenderCopy( sdlRenderer, sdlTexture, NULL, sdlRect); SDL_RenderPresent( sdlRenderer ); SDL_Delay(40); // 释放资源 sws_freeContext(img_convert_ctx); // 释放SWS_Scaler上下文#if OUTPUT_YUV420P fclose(fp_yuv); // 关闭YUV输出文件#endif SDL_Quit(); // 退出SDL子系统 av_frame_free(pFrameYUV); // 释放YUV帧的内存 av_frame_free(pFrame); // 释放原始帧的内存 avcodec_close(pCodecCtx); // 关闭编解码器上下文 avformat_close_input(pFormatCtx); // 关闭输入流上下文 return 0; // 程序成功退出","tags":["FFmpeg"],"categories":["technology"]},{"title":"CMakeLists中的常见字段","path":"/2025/06/07/CMakeLists常见字段/","content":"CMakeLists.txt 中的核心是一系列的命令（commands）和变量（variables）。通过这些命令，我们向 CMake 声明项目的各种特性和构建规则。 以下是一些 CMakeLists.txt 中最常见和重要的“字段”（或者说，命令和变量）： 核心项目配置命令 cmake_minimum_required(VERSION major.minor [FATAL_ERROR]) 作用： 指定项目所需的最低 CMake 版本。这是每个 CMakeLists.txt 文件的第一行。它确保你的项目不会在旧版本的 CMake 上编译，旧版本可能不支持你使用的某些命令或特性。 示例： cmake_minimum_required(VERSION 3.10) project(PROJECT_NAME [LANGUAGES language...] [VERSION major[.minor[.patch[.tweak]]]]) 作用： 定义项目的名称。这是顶级 CMakeLists.txt 中仅次于 cmake_minimum_required 的第二条命令。它也可能指定项目支持的语言（如 CXX, C, Fortran）和版本。 示例： project(simplest_ffmpeg_player CXX VERSION 1.0) 源文件、目标和依赖管理 add_executable(target_name [source1] [source2] ...) 作用： 定义一个可执行目标。这是最常见的命令之一，它告诉 CMake 将指定的源文件编译并链接成一个可执行程序。 示例： add_executable(my_app main.cpp helper.cpp) add_library(target_name [STATIC | SHARED | MODULE] [source1] [source2] ...) 作用： 定义一个库目标。你可以指定它是静态库 (STATIC)、动态库 (SHARED) 还是模块库 (MODULE)。 示例： add_library(my_static_lib STATIC static_func.cpp) add_library(my_shared_lib SHARED shared_func.cpp) target_sources(target [PRIVATE|PUBLIC|INTERFACE] source1 [source2] ...) 作用： 向一个已存在的 target 添加源文件。当源文件很多或需要根据条件添加时，这个命令比直接在 add_executableadd_library 中列出更灵活。 示例： target_sources(my_app PRIVATE main.cpp) target_include_directories(target [PRIVATE|PUBLIC|INTERFACE] [dir1] [dir2] ...) 作用： 指定某个目标（可执行文件或库）的头文件搜索路径。 PRIVATE：只影响当前目标本身的编译。 PUBLIC：影响当前目标本身的编译，也影响链接到此目标的任何其他目标。 INTERFACE：只影响链接到此目标的任何其他目标。 示例： target_include_directories(my_app PUBLIC $CMAKE_SOURCE_DIR/include) target_link_libraries(target [PRIVATE|PUBLIC|INTERFACE] [item1] [item2] ...) 作用： 指定某个目标需要链接的库。这可以是其他 CMake 目标，也可以是外部库。链接顺序在某些情况下很重要。 示例： target_link_libraries(my_app PRIVATE my_shared_lib Qt5::Widgets) add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 作用： 包含另一个子目录中的 CMakeLists.txt 文件。这对于组织大型项目结构非常有用。 示例： add_subdirectory(src) 变量和属性设置 set(variable value [CACHE type docstring [FORCE]]) 作用： 设置 CMake 变量的值。变量在 CMake 脚本内部使用，可以存储路径、选项等。CACHE 选项用于创建用户可以在 CMake GUI 或命令行中配置的缓存变量。 示例： set(SOURCE_FILES main.cpp) set(CMAKE_CXX_STANDARD 17) (设置C++标准，这是一个重要的内置变量) set(BUILD_SHARED_LIBS ON CACHE BOOL Build shared libraries FORCE) option(variable Help string [initial value]) 作用： 创建一个布尔选项，用户可以在 CMake 配置时启用或禁用。 示例： option(BUILD_TESTS Build unit tests ON) 查找包和依赖 find_package(PackageName [version] [REQUIRED] [COMPONENTS comp1 comp2...] [OPTIONAL_COMPONENTS comp3...] [NO_MODULE] [NO_CONFIG]) 作用： 查找并加载外部依赖包（如 Boost, OpenCV, Qt 等）。如果找到，它会设置一些变量（如 PackageName_FOUND，PackageName_INCLUDE_DIRS，PackageName_LIBRARIES）或导入目标（如 Qt5::Widgets）。 示例： find_package(SDL2 REQUIRED) 条件和循环控制流 if (...) ... elseif (...) ... else (...) ... endif() 作用： 条件语句，根据条件执行不同的命令。 示例： if(WIN32) message(Building on Windows)elseif(UNIX) message(Building on Unix-like system)endif() foreach(loop_var item1 [item2 ...] ) ... endforeach() 作用： 循环遍历列表。 示例： set(MY_SOURCES a.cpp b.cpp c.cpp)foreach(src_file $MY_SOURCES) message(Processing $src_file)endforeach() 其他常用命令 message([STATUS|WARNING|AUTHOR_WARNING|FATAL_ERROR|CHECK_START|CHECK_DONE|CHECK_FAIL] message to display) 作用： 在 CMake 配置过程中输出信息到控制台。对于调试和用户提示非常有用。 示例： message(STATUS Configuring $PROJECT_NAME project...) file(GLOB variable [LIST_DIRECTORIES true|false] [RELATIVE path] [pattern1] [pattern2] ...) 作用： 查找匹配给定模式的文件，并将结果存储到变量中。常用于收集源文件。 示例： file(GLOB SOURCE_FILES src/*.cpp src/*.c) 注意： 虽然方便，但 file(GLOB) 在某些情况下可能不是最佳实践，因为它不处理文件删除的情况（需要重新运行 CMake）。更推荐显式列出源文件或使用 target_sources。 install(...) 作用： 定义项目的安装规则，例如将可执行文件、库、头文件安装到系统目录或指定目录。 示例： install(TARGETS my_app DESTINATION bin)install(DIRECTORY include/ DESTINATION include)","tags":["CMake"],"categories":["technology"]},{"title":"音视频传输基础","path":"/2025/06/01/音视频/","content":"刚刚开始学习音视频相关的知识，在搜索学习资料的时候发现这个方向做的最多开源的是一位博士生雷霄骅。但是雷博士已经去世，这里表达敬意。文章记录从雷神的博客中自己理解的知识，其中有摘抄的博客内容 视频播放器原理视频播放器拓扑结构 解协议的作用，就是将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。解封装的作用，就是将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。解码的作用，就是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的音频抽样数据，例如PCM数据。视音频同步的作用，就是根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显卡和声卡播放出来。 流媒体协议 封装格式 视频编码 音频编码 名称 推出机构 推出时间 目前使用领域 LDAC Sony Corporation 2015 高分辨率无线音频传输，主要应用于索尼耳机播放器与安卓设备之间（需要设备支持） 关于LDAC的补充说明： 高分辨率音频传输： LDAC是索尼开发的一种音频编码技术，旨在通过蓝牙连接传输高分辨率（Hi-Res Audio）音频。它能够传输比传统蓝牙编解码器（如SBC）更高码率的数据，从而在无线传输中保留更多的音频细节。 码率： LDAC支持多种传输码率，最高可达990 kbps（在最佳连接条件下），这远高于SBC（最高约328 kbps）和aptX HD（576 kbps）。 应用场景： 主要用于索尼自家的音频产品（如WH-1000XM系列耳机、Walkman播放器）以及支持LDAC的安卓智能手机。它是安卓8.0（Oreo）及更高版本系统中的一个标准蓝牙音频编解码器。 局限性： 尽管LDAC能够传输高码率音频，但其传输质量受限于蓝牙连接的稳定性。在复杂的无线环境下，码率可能会自适应下降以维持连接。此外，其使用范围主要集中在索尼和安卓生态系统内，苹果iOS设备目前不支持LDAC。 与传统编码器的区别： 与你表格中列出的AAC、MP3、AC-3、WMA等主要用于音频文件存储和流媒体分发的编码器不同，LDAC更侧重于无线传输过程中的高质量编码，尤其是在蓝牙这个带宽有限的载体上。AAC、MP3等通常是音频文件的格式，而LDAC是传输协议的一部分，用于将这些格式的音频数据通过蓝牙高效传输。 什么是RTSP（流媒体协议）RTSP的组成RTSP是一个实时的传输协议，是一个应用层的协议，包RTSP协议，RTP协议，RTCP协议。 RTSP协议主要是负责建立服务器和客户端之间的请求和相应，建立通信链路。 RTP协议是负责在服务器和客户端进行传输数据， RTCP协议四负责提供RTP传输质量的反馈，确保RTP传输的质量。 三者的关系：RTSP不会发送媒体数据，知识完成服务器和客户端之间的信令交互，RTP协议负责媒体数据传输，RTCP负责RTP数据包的监视和反馈，RTP和RTCP并没有规定传输层的类型，可以选择UDP或者是TCP，RTSP则要求是基于TCP。总体来说，RTSP是建立在RTP和RTCP之上的。 RTSP的过程一次基本的RTSP操作过程是，首先，客户端线连接到流媒体服务器，并发送i个（DESCRIBE）。流服务器通过一个SDP描述来进行反馈，反馈信息包括流数量，媒体类型等信息，客户端在分析描述符后 ,并为每个流发送SETUP命令，这个命令来告诉服务器，客户端用于接收媒体数据的端口，流媒体连接建立完成后，客户端发送i个播放命令PLAY服务器就可以在UDP上传送媒体流，RTP包到客户端，在播放过程中客户端还可进行快进，快退，等操作。 RTSP与HTTP的关系 RTSP引入了几种新的方法，比如DESCRIBE、PLAY、SETUP 等，并且有不同的协议标识符，RTSP为rtsp 1.0,HTTP为http 1.1； HTTP是无状态的协议，而RTSP为每个会话保持状态； RTSP协议的客户端和服务器端都可以发送Request请求，而在HTTPF协议中，只有客户端能发送Request请求。 在RTSP协议中，载荷数据一般是通过带外方式来传送的(除了交织的情况)，及通过RTP协议在不同的通道中来传送载荷数据。而HTTP协议的载荷数据都是通过带内方式传送的，比如请求的网页数据是在回应的消息体中携带的。 使用ISO10646(UTF-8) 而不是ISO 8859-1，以配合当前HTML的国际化； RTSP使用URI请求时包含绝对URI。而由于历史原因造成的向后兼容性问题，HTTP1.1只在请求中包含绝对路径，把主机名放入单独的标题域中； RTSP协议格式文章 在client和server的连接中，还需要使用SDP描述符，连接中有关于SDP的协议说明。 TS封装或者FLV封装编码视频帧内编码视频编码词用压缩技术来减少码率，而压缩的理论依据主要来源于： 数据冗余，通过关联图像中的各像素，来实现无损压缩 视觉冗余，在人眼的可分辨范围外通过引入客观失真来实现有损压缩。 变换编码：首先将源图像切割，然后对切割后的小块进行DCT变换，这个小块叫做宏块，在对图像块经过DCT变换后的系数进行量化，在传送过程中只传递一部分数据。实现有损压缩。实现有损压缩。 视频帧间编码采用运动估计和运动补偿的方法来实现，第一步还是实现图像分割，然后在前一图像或者后抑恶图像某个搜索窗口的范围内未每一一个图像块寻找最为相似的图像块，通过计算这两个图像块的变换关系得到运动矢量。将两个图像块相减得到残差图像。前一个过程叫做运动估计，后一个过程叫做运动补偿。 编码器算法视频编码器能够自主的比较帧内预测和帧间预测的结果，选择出最佳结果，即模式选择。并且编码器应该对每个宏块能做出如下处理： 后向预测（使用未来的帧） 前向预测（使用过去的帧） 无帧间预测，仅帧内预测 完全跳过（帧内或帧间预测） 同时为了提高视频压缩质量，引入I帧、P帧、B帧。 I帧只使用本帧内数据编码，不需要考虑消除时间序列相关性。P帧使用前面的I帧或P帧来做运动估计和补偿。B帧使用前面的一个I帧或P帧，或后面一个I帧或P帧；来进行预测。使用B帧可以实现高压缩比。但是如果P帧和参考B帧遭到破坏，其他所有依赖于它们的帧就不能完整解码，这会直接导致视频故障。视频通常无法从此类问题中恢复。然而，当被破坏的视频流到达I帧，因为I帧被独立地编码解码，所以视频问题可以从I帧恢复。 在H264中图像以序列为单位进行组织，一个序列是一段图像编码后的数据流。 一个序列的第一个图像叫做IDR 图像（立即刷新图像），IDR 图像都是 I 帧图像。H.264 引入 IDR 图像是为了解码的重同步，当解码器解码到 IDR 图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列。这样，如果前一个序列出现重大错误，在这里可以获得重新同步的机会。IDR图像之后的图像永远不会使用IDR之前的图像的数据来解码。 一个序列就是一段内容差异不太大的图像编码后生成的一串数据流。当运动变化比较少时，一个序列可以很长，因为运动变化少就代表图像画面的内容变动很小，所以就可以编一个I帧，然后一直P帧、B帧了。当运动变化多时，可能一个序列就比较短了，比如就包含一个I帧和3、4个P帧。 在视频编码序列中，GOP即Group of picture（图像组），指两个I帧之间的距离，Reference（参考周期）指两个P帧之间的距离。两个I帧之间形成一组图片，就是GOP。 下面重点解释一下B帧预测的逻辑。 我们用一个简化的模型来描述 B 帧的预测过程。假设我们有一个 GOP 结构，例如：I B B P B B I。 当编码器处理某个 B 帧时，例如，在 P1 和 P2 之间的 B1 帧：P1 --- B1 --- P2 B帧的预测通常涉及以下步骤： 确定参考帧列表 (Reference Picture Lists)： 每个 B 帧在编码时会维护两个参考帧列表： List 0 (L0)： 包含在其显示时间戳之前的参考帧（通常是 I 或 P 帧）。 List 1 (L1)： 包含在其显示时间戳之后的参考帧（通常是 I 或 P 帧）。 这些参考帧可以是比当前 B 帧更早或更晚解码的 IP 帧。例如，对于 B1，P1 位于 L0，P2 位于 L1。 宏块或子块级别预测：B帧的预测是以宏块（Macroblock，16x16 像素）或更小的子块为单位进行的。对于当前 B 帧中的一个宏块： a. 向前预测 (Forward Prediction)： 编码器在 List 0 中的参考帧（例如 P1）中搜索与当前宏块最相似的区域。 找到最相似的区域后，计算出**运动矢量 (Motion Vector, MV)**，这个 MV 指示了从参考帧中的哪个位置到当前宏块位置的位移。 记录下这个运动矢量和对应的预测残差（当前宏块与向前预测结果的差异）。 b. 向后预测 (Backward Prediction)： 编码器在 List 1 中的参考帧（例如 P2）中搜索与当前宏块最相似的区域。 计算出另一个运动矢量 (MV’)。 记录下这个运动矢量和对应的预测残差。 c. 双向预测 (Bi-directional Prediction)： 这是 B 帧特有的强大功能。编码器会尝试结合 向前预测的结果 和 向后预测的结果 来生成一个更准确的预测。 加权平均： 最常见的方法是对向前预测和向后预测的结果进行加权平均。例如，如果 B1 刚好位于 P1 和 P2 的中间，可能会对两个预测结果各取 50% 进行叠加。 选择更好的预测模式： 编码器会比较三种预测模式（向前、向后、双向）产生的预测残差大小，选择残差最小的模式。残差越小，说明预测越准确，需要编码的数据量就越少。 编码残差和运动信息： 无论选择哪种预测模式，B 帧最终编码的都是预测残差（当前宏块的实际像素值与预测结果之间的差异）以及用于预测的运动矢量和参考帧索引。 由于预测残差通常包含的能量非常小（因为预测得很准确），所以经过变换、量化和熵编码后，数据量会非常小。 举例说明 假设我们有三帧画面，编码顺序和显示顺序可能如下： 显示顺序： F1 (I) - F2 (B) - F3 (P) - F4 (B) - F5 (P) 解码顺序（为了先解码参考帧）： F1 (I) - F3 (P) - F2 (B) - F5 (P) - F4 (B) 我们聚焦在 F2 (B帧) 如何编码： 解码 F1 (I帧)： F1 是一个完整的独立帧，不依赖其他帧。 解码 F3 (P帧)： F3 依赖 F1 进行预测。编码器从 F1 中找到 F3 各个宏块的相似区域，记录下运动矢量和残差。 解码 F2 (B帧)： F2 知道它在显示顺序上介于 F1 和 F3 之间。 对于 F2 中的一个宏块： 向前预测： 编码器在 F1 中找一个最像的块，记录 MV。 向后预测： 编码器在 F3 中找一个最像的块，记录 MV’。 双向预测： 将 F1 的预测块和 F3 的预测块进行平均或加权平均，形成一个双向预测块。 编码器会比较这三种方式的预测残差大小。例如，如果 F2 上的一个物体是从 F1 运动到 F3 过程中的中间位置，那么双向预测往往能得到最小的残差。如果 F2 上的一个静止背景在 F1 和 F3 中都有，那么向前或向后预测就足够了。 最终，F2 编码并存储：哪个预测模式、哪个参考帧（L0或L1）、运动矢量、以及实际的预测残差。 音频编码同样在音频方向也包括有损压缩和无损压缩。有损即去掉弱音信号或者去掉人耳听觉范围外的频率（20Hz||20KHz）. 关于音频的采样量化等方法以传统的PCM为例。 常见的无损方法： FLAC (Free Lossless Audio Codec): 目前最流行的无损音频编码格式，开源、免费。 APE (Monkey’s Audio): 另一种流行的无损格式，但解码复杂度较高。 ALAC (Apple Lossless Audio Codec): 苹果开发的无损格式，用于其生态系统。 WavPack (WV): 灵活的混合模式无损格式。 DSDDSFDFF: 用于高解析度音频的特殊无损格式，不完全是 PCM 编码。 有损方法较多，后面再详细学习，这里只聊一下AAC。 AAC编码文件格式文件有两种： ADIF：Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。 ADTS：Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。这种格式可以用于广播电视。 简言之。ADIF只有一个文件头，ADTS每个包前面有一个文件头。","tags":["音视频传输","RTSP","音视频编解码"],"categories":["technology"]},{"title":"MCP中的细节问题","path":"/2025/05/23/MCP/","content":"MCP协议以及其中的客户端和服务器 首先附上up画的对我启发极大的一张图片。这张图片中讲了各大部件之间的关系。 从MCP协议为起点，MCP（Model Context Protocol），即模型上下文协议，正是这样一个旨在解决大型语言模型（LLM）与外部世界交互问题的开放标准。 MCP采用客户端-服务器（Client-Server）架构模式： Host（主机）LLM 应用： 代表大型语言模型应用程序，例如Claude Desktop、Cursor等，它们是发起连接的一方。 Client（客户端）： 在Host应用程序内部负责与MCP服务器建立连接，其实可以理解成Agent与MCP协议的集合。 MCP Server（MCP服务器）： 这是MCP系统中最关键的环节。它是一个程序，提供工具和数据访问能力供LLM使用。MCP服务器可以作为本地应用运行在用户设备上，也可以部署到远程服务器。每个MCP服务器都提供一组特定的工具（Tools）、资源（Resources）和提示（Prompts）： 1. 工具（Tools）： 供AI模型调用的函数或操作，例如查询数据库、发送邮件、执行代码等。在面对一些没有提供程序接口的软件的时候，可以考虑写一些Py脚本或者命令行工具来实现我们的需求，例如打开项目文件，修改模型参数，运行仿真，提取仿真结果等。另外一种方式，时可以选择一些自动化的GUI库，这样的话就需要很多OCR的token了2. 资源（Resources）： 供用户或AI模型使用的上下文和数据，例如API回复、文件内容等。3. 提示（Prompts）： 用于完成特定任务的预定义提示模板。当LLM需要获取信息或执行操作时，它会通过MCP客户端向MCP服务器发送请求。MCP服务器会与相应的外部数据源或工具进行交互，获取数据并按照MCP协议规范进行格式化，最后将格式化后的数据返回给LLM。 回到上图，由于这个协议是用来规范Agent和各种tools之间的通信，调用格式规范的，由此可以将客户端的开发与服务器的开发分离开。因此开发可以分成三个大部分， 大模型部分的工作与RAG架构第一个部分是大模型部分，包括微调、如何设计一个专用模型，如何减少幻觉、目前的RAG架构如何进行优化等等工作。 简单介绍一下RAG架构 想象一下，LLM就像一个博览群书但只活在“过去”的人（因为它的知识截止于训练数据）。RAG给它配了一个“实时图书馆管理员”和一套“搜索工具”。 RAG核心思路：当用户提出一个问题时，RAG不是直接让LLM回答，而是分两步走： 检索 (Retrieval)： 从一个外部知识库（你的“实时图书馆”）中找出与用户问题最相关的几段信息。 增强生成 (Augmented Generation)： 将这些检索到的信息和用户的问题一起喂给LLM，让LLM基于这些“上下文”来生成答案。 RAG架构详解与举例：假设你正在研究一个新的相控阵天线设计，并且你有一个内部的技术文档库，里面包含了最新的天线设计规范、材料特性和仿真结果。 用户问题： “最新的MIMO相控阵天线设计中，氮化镓（GaN）材料的关键优势是什么？” 第一步：知识库准备 (提前进行)这是RAG的基础，你需要把你的“实时图书馆”整理好。 文档收集： 收集所有相关的技术文档、研究论文、设计规范等。 Chunking (分块)： 概念： 大文档被分割成更小的、有意义的文本片段，称为“Chunk”（块）。 目的： LLM的输入有长度限制（上下文窗口），而且太大的块会稀释关键信息。把文档切成小块，可以更精准地检索。 举例： 你的一篇关于GaN材料特性的长论文，会被切分成多个Chunk，例如： Chunk 1: “GaN在射频（RF）应用中的基本特性和历史…” Chunk 2: “GaN在MIMO相控阵天线中的功率密度和效率优势…” Chunk 3: “GaN与其他半导体材料（如GaAs）的对比…” Chunk 4: “GaN器件的散热挑战和解决方案…” 切分策略： 可以按句子、段落、固定长度（带重叠）等方式切分。对于技术文档，考虑语义完整性很重要。 Embedding (嵌入)： 概念： 将每个文本Chunk转换成一个高维的数字向量（一串数字），这个向量能够捕捉Chunk的语义信息。语义相似的Chunk，它们的Embedding向量在向量空间中也会靠得很近。 技术： 使用专门的Embedding模型（例如OpenAI的text-embedding-ada-002，或者开源的BERT、Sentence-BERT等模型）来完成。 举例： Chunk 1的Embedding向量：$[0.1, -0.5, 0.3, …, 0.8]$ Chunk 2的Embedding向量：$[0.15, -0.48, 0.32, …, 0.79]$ (与Chunk 1在向量空间中距离较近，因为都与GaN相关) Chunk 3的Embedding向量：$[0.6, 0.2, -0.1, …, 0.9]$ (与前两个距离较远，主题不同) 存储： 这些Embedding向量会被存储在一个向量数据库（Vector Database，如Pinecone, Weaviate, Milvus, ChromaDB等）中，以便快速检索。 第二步：实时查询 (当用户提问时) 用户问题Embedding： 当用户提出问题 “最新的MIMO相控阵天线设计中，氮化镓（GaN）材料的关键优势是什么？” 时，首先会使用与Chunk Embedding相同的Embedding模型将这个问题也转换成一个Embedding向量。 举例： 问题的Embedding向量：$[0.12, -0.51, 0.31, …, 0.81]$ 向量相似度搜索 (Retrieval)： 将用户问题的Embedding向量与向量数据库中所有Chunk的Embedding向量进行比较。 寻找语义上最相似的Chunk（即向量距离最近的Chunk）。 举例： 向量数据库会找出 Chunk 2 (“GaN在MIMO相控阵天线中的功率密度和效率优势…”) 和其他几个与GaN或MIMO相关的Chunk，因为它们的向量与问题向量距离最近。通常会检索Top-K个（比如Top-3或Top-5）最相关的Chunk。 增强生成 (Augmented Generation)： 将检索到的相关Chunk的原文内容（不是Embedding向量）和用户的问题一起打包成一个Prompt，发送给LLM。 Prompt结构示例： 请根据以下提供的信息，回答用户的问题：---信息1：[Chunk 2 的原文内容] GaN在MIMO相控阵天线中的功率密度和效率优势使其成为关键材料。其高击穿电压和电子迁移率，使得GaN器件能够工作在更高的频率和功率水平，从而实现更紧凑、更高性能的天线模块...信息2：[Chunk 5 的原文内容] 此外，GaN在高温下的稳定性也优于其他半导体材料，这对于MIMO天线在高功率运行时的散热设计至关重要...---用户问题：最新的MIMO相控阵天线设计中，氮化镓（GaN）材料的关键优势是什么？ LLM接收到这个“增强”后的Prompt，它现在不仅有自己原有的知识，还有了来自外部知识库的最新、最具体的信息。 LLM结合这些信息进行理解、推理和生成，给出更准确、更专业的答案。 LLM的最终回答： “在最新的MIMO相控阵天线设计中，氮化镓（GaN）材料的关键优势体现在其高功率密度、高效率以及在高温下的卓越稳定性。GaN的高击穿电压和电子迁移率使其能在更高频率和功率水平下运行，从而实现更紧凑、高性能的天线模块。此外，其优异的热稳定性对高功率MIMO天线的散热设计至关重要。” 但是就像我之前读过的一个知乎大佬所写的文章所说的，能不自己部署模型，就不自己部署。 自己部署的硬件成本和维护成本，对于小团队来说，很可能是压垮骆驼的一座大山。 Agent开发第二个是Agent的开发部分，也就是客户端部分，关于这部分已经写过一些内容了。 这里还应该注意的是，由于MCP协议，其实不需要关注agent输入与输出的设计，只需要根据不同的业务场景选择，Agent的输出究竟选择JSON格式还是选择使用Prompt格式即可，如何设计Prompt也就成了重点。 服务器部分第三个是服务器部分，未来会在这个方向做一些探索。 这里包含很多的部分，像Tools的设计，也就是如何根据业务场景写一个函数的库来供Agent进行调用。另外在写库函数时要格外注意docstr的书写，函数变量的命名，这里其实和Prompt设计有异曲同工之妙了。 最后，一些思考。关于整套架构，其中的工具设计是比较容易做到的（除了大模型部分的算法部分），但是如何为MCP的落地提供应用场景就成了难事，巨大的token耗费成本极大的限制了应用场景，如何落地呢？","tags":["MCP"],"categories":["technology"]},{"title":"C++中的STL标准库","path":"/2025/05/05/STL_r1_output/","content":"C++ STL标准库源码解析与设计思想 最近在学习侯捷老师关于STL源码的解析（以GNU 2.9实现为例），本文记录核心知识点与设计哲学 一、STL六大组件全景图 STL主要分成了六个部分，其中包括容器，迭代器，分配器，算法，仿函数以及一些适配器。在学习STL之前应该首先对泛型编程以及对象编程有清晰的认识，对象编程倾向于设计一个Class类，实现一个具备自身数据和自身功能的一个整体，并提供复用的接口。泛型编程广泛的应用了模板的相关知识，通过模板参数T或者Foo来分别设计函数和数据的具体实现。对于不同版本的库文件，各家的编写方式也不尽相同，例如VC库文件和GNU库文件。同时由于标准规范存在，代码能够有较好的可移植性 STL（Standard Template Library）由以下六大核心组件构成： 容器（Containers）：管理数据的集合（如vector、list、map） 迭代器（Iterators）：泛化的指针，提供容器元素的访问接口 分配器（Allocators）：内存管理的底层实现（如std::alloc） 算法（Algorithms）：通用算法（如sort、find） 仿函数（Functors）：行为类似函数的对象（如lessT） 适配器（Adapters）：组件接口转换器（如stack、queue） 容器主要分成关联式和序列式容器，对于序列是容器能够支持一些排序等操作。而关联式容器支持快速的查找工作在学习容器部分的时候应该格外关注他们的底层实现，这关乎于不同算法的实现效率，另外以及内存占用情况，以及容器内部定义的可以调用的一些基本函数。注意容器内部定义的一些函数和全局定义的函数的区别，例如find、sort等函数。 对于vector是使用三个指针进行控制，头部指针，内容尾部指针，以及内存尾部指针。vecotr的迭代器，不必设计成一个类。 deque是使用分段连续实现前后端均可以扩充对于deque的迭代器，使用四个属性进行控制。cur.first.last,node,deque的底层索引表也是通过vector来写的，进行二倍增长 stack 和queue的底层都是采用qeque来实现的。两者都不允许进行遍历，那么就是不提供迭代器 不同的容器其本身由于包括了多个迭代器，其指针等其本身就占用多个字节，例如deque占用40个字节，其内容要根据动态分配分配内存。需要注意的是，deque查找等动作，都需要首先检查指针是否已经在边界，进行索引表的步进，然后进行具体查找。 红黑树和散列表是关联式容器实现的关键。红黑树是一种平衡的二元搜寻树。不应该使用迭代器改变红黑树的元素值。因为红黑树内部有一定的排序规则。红黑树有多个参数，其中包括key，value，KeyOfValue,compare,alloc。红黑树内部有两种插入方式，包括insert_equal和insert_unique 二、容器实现深度解析2.1 序列式容器 容器 底层结构 关键特性 vector 动态数组 三指针控制：start, finish, end_of_storage deque 分段连续+索引表 迭代器含cur, first, last, node指针 list 双向链表 节点含prev, next, data指针 vector内存增长示例： vectorint v;v.push_back(1); // 容量1v.push_back(2); // 容量2（翻倍）v.push_back(3); // 容量4（再次翻倍） 2.2 关联式容器graph TD A[关联式容器] -- B[红黑树实现] A -- C[哈希表实现] B -- set/multiset B -- map/multimap C -- unordered_set C -- unordered_map 红黑树关键特性： 每个节点非红即黑 根节点必须为黑 红色节点的子节点必须为黑 任意节点到叶子的路径包含相同数量黑节点 三、迭代器设计哲学3.1 迭代器核心接口templateclass Tstruct iterator typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T reference; typedef random_access_iterator_tag iterator_category;; 迭代器是一种泛化的指针。要注意迭代器内部操作符重载的写法，例如++操作符、*、等重载的具体实现。另外以及iterator中的设计原则，iterator必须提供五种Type。这些参数在 iterator 头文件中通过 iterator 结构体定义，并在自定义迭代器时需要用到。这五个参数按顺序分别是： value_type: 迭代器所指向的元素的类型。通过迭代器，我们可以访问到容器中存储的元素，而 value_type 就定义了这些元素的类型。例如，对于 std::vectorint::iterator，其 value_type 就是 int。 difference_type: 用于表示迭代器之间距离的类型。通常情况下，这个类型是带符号的整型，例如 std::ptrdiff_t。它可以用来计算两个迭代器之间的元素个数。例如，如果你有两个指向 std::vectorint 中不同元素的迭代器 it1 和 it2，那么 it2 - it1 的结果类型就是 difference_type。 pointer: 指向 value_type 的指针类型。通常情况下，它是 value_type*。这个类型在某些迭代器（例如原始指针迭代器）中直接使用。 reference: 指向 value_type 的引用类型。通常情况下，它是 value_type。当我们通过解引用迭代器（使用 * 运算符）访问元素时，得到的就是一个 reference 类型的对象。 iterator_category: 描述迭代器所支持的操作的标签类型。STL 定义了五种主要的迭代器类别，它们之间存在着功能上的包含关系： std::input_iterator_tag: 只支持单向读取操作，即只能使用 *it 读取元素，并使用 ++it 使迭代器前进。输入迭代器通常用于单次遍历的输入流。 std::output_iterator_tag: 只支持单向写入操作，即只能使用 *it = value 写入元素，并使用 ++it 使迭代器前进。输出迭代器通常用于单次遍历的输出流。 std::forward_iterator_tag: 支持输入迭代器的所有操作，并且可以多次遍历容器中的元素。这意味着你可以保存一个前向迭代器的副本，并在之后再次使用它从相同的位置开始遍历。 std::bidirectional_iterator_tag: 支持前向迭代器的所有操作，并且可以双向移动，即可以使用 --it 使迭代器后退。std::list、std::set 和 std::map 等容器的迭代器通常是双向迭代器。 std::random_access_iterator_tag: 支持双向迭代器的所有操作，并且提供随机访问的能力。这意味着你可以像操作数组指针一样，使用 it + n、it - n、it[n] 以及比较运算符（、、=、=）在常数时间内访问任意位置的元素。std::vector、std::deque 和数组的迭代器都是随机访问迭代器。 3.2 迭代器分类与能力 迭代器类型 支持操作 典型容器 随机访问迭代器 ++, --, +n, -n, [] vector, deque 双向迭代器 ++, -- list, setmap 前向迭代器 ++ forward_list 输入输出迭代器 单次遍历 istream, ostream 对于STL的容器等部件实际上是一个类模板，而算法实际上是一个函数的模板。另外函数一般会有多个重载方式，通过参数类型、数量等来区分。算法只会接收迭代器，看不到容器，所以它所需要的所有信息必须从迭代器中获得，而迭代器必须能够回答算法的所有问题。 四、算法与仿函数协作机制4.1 算法模板示例template class InputIterator, class TInputIterator find(InputIterator first, InputIterator last, const T value) while (first != last *first != value) ++first; return first; 仿函数（functors），仿函数是通过设计一种类通过重载小括号来近似实现函数的功能，是为算法进行服务的，分别有算术类，逻辑运算类，以及相对关系类。例如针对自定义的一种类，来定义一种独特的排序方式。 再STL中规定了每个Adaptor都应该挑选一个适配者继承，因为在函数应用到仿函数的时候很有可能会询问仿函数一些基础参数问题，因此需要像迭代器那样，给它一个继承的身份。 4.2 仿函数与适配器算术仿函数示例： template class Tstruct plus : binary_functionT, T, T T operator()(const T x, const T y) const return x + y; ; 适配器应用场景： // 将普通函数转换为仿函数ptr_fun(my_function); // 绑定参数bind2nd(lessint(), 40); 五、内存管理：分配器实现5.1 GNU 2.9 allocator设计class __malloc_alloc_template // 一级分配器 static void* allocate(size_t n) /* 直接调用malloc */ ;class __default_alloc_template // 二级分配器 enum __ALIGN = 8 ; static size_t ROUND_UP(size_t bytes) return (((bytes) + __ALIGN-1) ~(__ALIGN - 1)); ; 5.2 内存池工作流程 维护16个自由链表（$8-128$字节） 内存不足时向系统申请大块内存 碎片回收通过自由链表管理 六、STL设计精髓总结 泛型编程思想：通过模板实现算法与数据类型的解耦 低耦合高内聚：容器、迭代器、算法通过标准接口协作 效率优先：通过内存池、红黑树等结构优化性能 可扩展性：允许用户自定义分配器、仿函数等组件","tags":["C++,STL"],"categories":["technology"]},{"title":"MiniAgi源码阅读笔记","path":"/2025/05/03/MiniAgi 源码阅读/","content":"spinner.py在这个文件中定义了一个光标效果 def spinner_task(self): while self.busy: sys.stdout.write(next(self.spinner_generator)) sys.stdout.flush() #强制立即刷新 time.sleep(self.delay) # 定义帧率 sys.stdout.write(\\b) # 光标回退， 实现覆盖字符 sys.stdout.flush() def __enter__(self): # 启动动画线程 self.busy = True threading.Thread(target=self.spinner_task).start()def __exit__(self, exception, value, tb): #停止动画 self.busy = False time.sleep(self.delay) if exception is not None: return False return True exceptions.py这个文件主要是用来捕获模型输出中的异常，例如格式不对，缺字段，非json等。然后将这个异常抛回给上层进行处理。继承了python内置的Exception类 class InvalidLLMResponseError(Exception): Exception raised when the LLM response cant be parsed. Attributes: None commond.py在这个文件中规定了不同命令的思考链 库文件说明 import subprocess 作用：用于创建子进程，执行外部命令或脚本，并获取其输入输出结果。 典型用途： 调用系统命令（如 ls, ping, gcc, python 等）； 执行外部程序或脚本（如 shell 脚本、批处理）； 控制输入输出重定向。 from io import StringIO 作用：提供一个类 StringIO，它创建一个内存中的字符串缓冲区，可像文件一样读写。 典型用途： 在不涉及实际文件的情况下模拟文件操作； 用于测试代码中涉及文件读写的部分； 捕捉输出文本（通常与 redirect_stdout 配合使用）。 from contextlib import redirect_stdout 作用：上下文管理器，用于临时将标准输出重定向到指定对象（比如 StringIO）。 典型用途： 捕捉 print() 语句的输出； 在测试或调试中查看函数内部输出； 搭配 StringIO 捕获控制台输出为字符串处理。 from duckduckgo_search import DDGS 作用：导入 DuckDuckGo Search 的 Python 接口 DDGS 类，用于调用 DuckDuckGo 的搜索功能。 典型用途： 用代码直接进行 DuckDuckGo 搜索并获取结果； 抓取网页搜索摘要、链接、图像等； 用于构建搜索引擎接口或信息爬取工具。 class类说明在execute_commond中首先将命令进行分发 if command == memorize_thoughts: 调用 Commands.memorize_thoughts(arg)elif command == execute_python: 调用 Commands.execute_python(arg)...else: 返回 Unknown commandcommond如果过程中出现异常，返回异常信息 然后分别定义各个函数内容 miniagi.pyprompt设计关于prompt的具体设计原则，会写另外一篇博客进行说明在MiniAgi项目中prompt的设计是这样的设计中融入了思维链、少样本提示，并且强调了自我一致性。同时，在prompt的设计中加入了自我批评CRITIC_PROMPT，以及记忆重整HISTORY_SUMMARY_HINT等。具体如下 角色设定（Role Conditioning）fYou are an autonomous agent running on operating_system. 明确模型的“身份”：你是运行在某操作系统上的自主代理智能体；通过设定操作系统，有利于后续与 Shell 命令、文件路径等交互时保持一致（如 Linux vs Windows）。 目标导向任务（Objective Conditioning） OBJECTIVE: objective (e.g. Find a recipe for chocolate chip cookies) 为当前任务设定一个清晰目标，使模型行为聚焦； 模仿人类代理行为，把目标当成“长期任务”，以实现规划式思维。 历史上下文注入（Context）Previous steps: context 引入以往已执行的动作观察结果，作为“记忆”或状态追踪； 支持多步推理和上下文保持，是链式思维（Chain-of-Thought）的关键。 明确命令集（命令语言接口设计） 定义一个有限状态机风格的 API 接口，明确智能体能执行的动作范围； 强制每一步只能执行一个命令，避免无控制的自然语言混乱； 命令覆盖典型任务：记忆、推理、代码执行、数据处理、与用户对话、终止。 明确格式约束（动作语法模板） r[YOUR_REASONING]/rc[COMMAND]/c[ARGUMENT] r：模型的推理或动机说明； c：结构化命令名称（对应预定义命令集）； [ARGUMENT]：命令参数； 该格式是构化动作标注，利于解析、监督、记录、回放等； 防止输出中出现自然语言噪声或模糊行为。 行为限制与安全提示 不要重复命令 不要链式多个命令 Python 要以 print 输出结尾 process_data ingest_data 只能处理单文件 不搜索 GPT 已知知识 保证行为唯一性、可解释性、可控性； 限制模型可能的幻觉或冗余行为； 强化对命令执行前提条件的检查（如输出格式约束）。 示例示范（Few-shot Prompting） rThink about skills and interests.../rcmemorize_thoughts/crSearch for websites.../rcweb_search/c 提供多个风格统一、结构良好的行为范例； 用作 few-shot learning 的提示模板，让模型模仿人类代理行为； 示例覆盖了多种命令使用方式、输入格式、常见应用。 MiniAgi类class MiniAGI: 表示一个自主智能体（Agent）类。 属性（Attributes）定义了 agent 的各种组件和运行状态。 def __init__( # 参数初始化列表 self, agent_model: str, summarizer_model: str, objective: str, max_context_size: int, max_memory_item_size: int, debug: bool = False ): 构造函数：创建 MiniAGI 实例，初始化内部模型和参数。 # 初始化用于生成行为的主模型 self.agent = ThinkGPT( model_name=agent_model, request_timeout=600, verbose=False ) # 初始化用于生成摘要的模型 self.summarizer = ThinkGPT( model_name=summarizer_model, request_timeout=600, verbose=False ) # 保存目标、内存限制、是否调试等配置参数 self.objective = objective self.max_context_size = max_context_size self.max_memory_item_size = max_memory_item_size self.debug = debug # 以下是状态相关的字符串属性，初始设为空 self.summarized_history = self.criticism = self.thought = self.proposed_command = self.proposed_arg = # 使用 tiktoken 获取模型的 tokenizer 编码器 self.encoding = tiktoken.encoding_for_model(self.agent.model_name) def __update_memory(self, action: str, observation: str, update_summary: bool = True): 内部方法：根据行动和观察结果更新记忆。 如果 observation 太长，会先进行摘要处理。 # 如果 observation 超过允许大小，进行摘要 if len(self.encoding.encode(observation)) self.max_memory_item_size: observation = self.summarizer.chunked_summarize( observation, self.max_memory_item_size, instruction_hint=OBSERVATION_SUMMARY_HINT ) # 构造新记忆格式 if memorize_thoughts in action: new_memory = fACTION: memorize_thoughts THOUGHTS: observation else: new_memory = fACTION: action RESULT: observation # 如果需要更新摘要，调用 summarizer 的 summarize 方法 if update_summary: self.summarized_history = self.summarizer.summarize( fCurrent summary: self.summarized_history Add to summary: new_memory, self.max_memory_item_size, instruction_hint=HISTORY_SUMMARY_HINT ) # 将新记忆交由 agent 存储 self.agent.memorize(new_memory) def __get_context(self) - str: 内部方法：构造 agent 当前的上下文字符串。 上下文包括摘要、最近的行为和批评。 summary_len = len(self.encoding.encode(self.summarized_history)) criticism_len = len(self.encoding.encode(self.criticism)) if self.criticism else 0 # 从 agent 中获取最多能容纳的最近记忆片段 action_buffer = .join( self.agent.remember( limit=32, sort_by_order=True, max_tokens=self.max_context_size - summary_len - criticism_len ) ) # 构建最终上下文字符串 return fSUMMARY self.summarized_history PREV ACTIONS: action_buffer self.criticism def criticize(self) - str: 调用模型对 agent 最近的行为进行批评。 context = self.__get_context() self.criticism = self.agent.predict( prompt=CRITIC_PROMPT.format(context=context, objective=self.objective) ) return self.criticism def think(self): 调用模型进行推理，生成下一步操作计划。 context = self.__get_context() if self.debug: print(context) # 基于 prompt 和上下文生成原始响应 response_text = self.agent.predict( prompt=PROMPT.format(context=context, objective=self.objective) ) if self.debug: print(fRAW RESPONSE: response_text) # 使用正则表达式提取 r思考/rc命令/carg PATTERN = r^r(.*?)/rc(.*?)/c *(.*)$ try: match = re.search(PATTERN, response_text, flags=re.DOTALL | re.MULTILINE) _thought = match[1] _command = match[2] _arg = match[3] except Exception as exc: raise InvalidLLMResponseError from exc _arg = _arg.replace(```, ) # 去除可能的 markdown 格式符号 # 保存模型推理结果 self.thought = _thought self.proposed_command = _command self.proposed_arg = _arg def read_mind(self) - tuple: 获取 agent 最近的思考、命令和参数。 _arg = self.proposed_arg.replace( , \\ ) if len(self.proposed_arg) 64\\ else fself.proposed_arg[:64]....replace( , \\ ) return (self.thought, self.proposed_command, _arg) @staticmethod def __get_url_or_file(_arg: str) - str: 根据参数读取 URL 或本地文件内容。 if _arg.startswith(http://) or _arg.startswith(https://): with urlopen(_arg) as response: html = response.read() data = BeautifulSoup(html, features=lxml).get_text() else: with open(_arg, r) as file: data = file.read() return data def __process_data(self, _arg: str) - str: 对 URL 或文件进行处理，格式为：prompt|url或文件路径 args = _arg.split(|) if len(args) == 1: return Invalid command. The correct format is: prompt|file or url if len(args) 2: return Cannot process multiple input files or URLs. Process one at a time. prompt, __arg = args try: input_data = self.__get_url_or_file(__arg) except urllib.error.URLError as e: return fError: str(e) except OSError as e: return fError: str(e) if len(self.encoding.encode(input_data)) self.max_context_size: input_data = self.summarizer.chunked_summarize( input_data, self.max_context_size, instruction_hint=OBSERVATION_SUMMARY_HINT ) return self.agent.predict( prompt=fRETRIEVAL_PROMPT prompt INPUT DATA: input_data ) def __ingest_data(self, _arg: str) - str: 只读取 URL 或文件内容（不进行指令解析），返回文本或摘要。 try: data = self.__get_url_or_file(_arg) except urllib.error.URLError as e: return fError: str(e) except OSError as e: return fError: str(e) if len(self.encoding.encode(data)) self.max_memory_item_size: data = self.summarizer.chunked_summarize( data","tags":["Agent"],"categories":["technology"]},{"title":"Prompt设计（2）","path":"/2025/05/02/prompt设计(2)/","content":"零样本提示提示 将文本分类成中性、负面或正面文本：我认为这次假期还可以情感： 输出 中性 指令调整已被证明可以改善零样本学习Wei等人（2022）。指令调整本质上是在通过指令描述的数据集上微调模型的概念。此外，RLHF（来自人类反馈的强化学习）已被采用以扩展指令调整，其中模型被调整以更好地适应人类偏好。这一最新发展推动了像ChatGPT这样的模型。我们将在接下来的章节中讨论所有这些方法和方法。 少样本提示即在prompt中给出一个实例，来帮助模型进行理解 这太棒了！// Negative这太糟糕了！// Positive哇，那部电影太棒了！// Positive多么可怕的节目！// Negative COT 关于零样本COT：即在后面加入”让我们逐步思考” 自动思维链（Auto-Cot），即利用 LLMs “让我们一步一步地思考” 提示来生成一个接一个的推理链。这种自动过程仍然可能在生成的链中出现错误。为了减轻错误的影响，演示的多样性很重要。 一般首先要先将任务分解成为不同的、连续的步骤 使用XML来构建清晰的交接 对每个任务要求构建清晰的目标 要根据模型的表现进行Prompt的迭代 自我一致性自我一致性旨在“替换链式思维提示中使用的天真贪婪解码方法”。其想法是通过少样本 CoT 采样多个不同的推理路径，并使用生成结果选择最一致的答案。这有助于提高 CoT 提示在涉及算术和常识推理的任务中的性能。其实本质上是设计相同范式的问题与解答，帮助模型建立一致性 Q：林中有15棵树。林业工人今天将在林中种树。完成后，将有21棵树。林业工人今天种了多少棵树？ A：我们从15棵树开始。后来我们有21棵树。差异必须是他们种树的数量。因此，他们必须种了21-15 6棵树。答案是6。 Q：停车场有3辆汽车，又来了2辆汽车，停车场有多少辆汽车？ A：停车场已经有3辆汽车。又来了2辆。现在有3 + 2 5辆汽车。答案是5。 …. 当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？ TOTTOT本质上是将思考过程建模成一个多步，分支的思考树。每个节点都是一个思考过程。可以通过合理设计Prompt来实现TOT的结构。目前较为流行的TOT结构包括基于深度搜索、广度搜索等策略的。另一种基于强化学习训练出的TOT训练器。假设三位不同的专家来回答这个问题。所有专家都写下他们思考这个问题的第一个步骤，然后与大家分享。然后，所有专家都写下他们思考的下一个步骤并分享。以此类推，直到所有专家写完他们思考的所有步骤。只要大家发现有专家的步骤出错了，就让这位专家离开。请问...如何将TOT应用于模型的建构中是下一步要了解的方向自动推理并使用工具（ART）是在2023年提出的一个新的框架，这个框架使用冻结的LLM来自动生成包含中间推理步骤的程序 在接到新的任务的时候，从任务库中选择多部推理和使用工具的示范 在测试中，调用外部工具，先暂停生成，将工具整合后继续生成 就目前所了解到的，基本的Prompt设计主要还是基于普通的设计，或加入一些思维链提示链等。另外还有一部分为了提高泛化性能，使用了LLM来生成prompt进而生成答案，","tags":["prompt"],"categories":["technology"]},{"title":"Prompt设计（1）","path":"/2025/05/01/prompt设计/","content":"prompt是用户输入给LLM的文本信息，是用来明确告知模型想要解决的问题，或者完成的任务。市面上已经有了一些关于prompt扩写、完善的工具，例如百炼。另外对prompt的设计实际上是一个迭代过程，可以通过openai等平台的playground进行大量的试验。在prompt中避免说不要做什么，而是应该要做什么。要非常具体地说明你希望模型执行的指令和任务。提示越具描述性和详细，结果越好。特别是当你对生成的结果或风格有要求时，这一点尤为重要。不存在什么特定的词元（tokens）或关键词（tokens）能确定带来更好的结果。更重要的是要有一个具有良好格式和描述性的提示词。事实上，在提示中提供示例对于获得特定格式的期望输出非常有效。 在设计提示时，还应注意提示的长度，因为提示的长度是有限制的。想一想你需要多么的具体和详细。包含太多不必要的细节不一定是好的方法。这些细节应该是相关的，并有助于完成手头的任务。这是你需要进行大量实验的事情。我们鼓励大量实验和迭代，以优化适用于你应用的提示。 基础结构较为通用的prompt结构如下： 输出：应该明确指出模型的输出内容的具体形式，确保LLM的输出能够满足后续的需求。 受众：需要明确指出面向的读者群体。以及适用的平台，在输出代码时可以有好的兼容性。 优化prompt 在prompt中提供期望的输出样例，可以让LLM模仿我们所要求的规范、格式、概念等要求进行输出。同时也能够使输出更加的统一。从而稳定模型表现。背景你很擅长编写小红书种草笔记，喜欢增加丰富的emoji元素。目的请生成一篇小红书种草笔记，推广强森吹风机。吹风机的优点是：体积小、高颜值、风力大、干得快、智能控温不伤发。受众喜欢追求时尚的年轻人，尤其是年轻女性输出小红书文章格式，充满emoji元素，简洁但内容充实语气与风格（提供了几种示例）我亲测过+n种好物+谁适合谁受益 这个秘诀让你的话语超有信服力！ 比如：亲自尝试了很多美白神器，终于挖到宝！仅俩月，肌肤变得嫩滑透亮，自我感觉飘飘欲仙~ 此法特为想大晒体验的小伙伴们量身定制，还能精准安利，助人避坑！难题出没+揭秘原因+终极解药 这公式助你条理清晰地分享，内容价值爆棚！ 案例：渴望秀发如丝？揭秘时刻来啦！原来我一直遗漏关键一步，直到遇见它！换用这款洗发水，秀发显著改善，光泽get！ 此法逻辑严密，不仅分享秘籍，还引导读者找到问题破解之道。独到见解+深度剖析+巧妙推荐 这公式帮你自然流露心声，还能温馨种草！ 示例：我觉得每个女孩都该有份挚爱，生活因此而精彩。手帐成了我的小确幸，每当提笔，幸福指数飙升！ 它助你畅所欲言，同时不经意间传递心头好，双赢策略！亲身经历+成果展示 这公式让你的情感表达鲜活又感人！ 场景：回想起夏夜海边的蚊灾，满身红包的绝望，直到遇见救星！现在，光滑肌肤让我裙摆飞扬，自信回归！ 它让你的故事活灵活现，分享喜悦与感恩之情，触动人心！ 而对于复杂任务，为LLM设定一个任务完成的步骤是十分重要的。（但如何设计一个泛化能力更强的任务步骤） 使用不常见的分隔符号来区分内容区域的界限标识。在构建复杂的 Prompt 时，采用特定的分隔符来界定不同内容单元是极为关键的，这一做法显著增强了 LLM 对 Prompt 正确解析的能力。随着任务复杂度的增加，合理利用分隔符越能提升 LLM 的表现。分隔符的选择应着眼于那些在自然语言文本中罕见的、独特的字符组合，例如：###、===、等。这些特殊符号序列并无固定规则，关键在于其辨识度高，确保模型能够明确区分这些符号是作为内容区域的界限标识，而非文本中的普通标点或语法组成部分。 思维链和提示链我们可以通过要求输出整个的推理过程进行思维链，另外还有思维树，Boosting of thought等。 另：文生图prompt指南提示词 主体（主体描述）+ 场景（场景描述）+ 风格（定义风格）+ 镜头语言 + 氛围词 + 细节修饰 主体描述：确定主体清晰地描述图像中的主体，包括其特征、动作等。例如，“一个可爱的10岁中国小女孩，穿着红色衣服”。场景描述：场景描述是对主体所处环境特征细节的描述，可通过形容词或短句列举。定义风格：定义风格是明确地描述图像所应具有的特定艺术风格、表现手法或视觉特征。例如，“水彩风格”、“漫画风格”常见风格化详见下方提示词词典。镜头语言：镜头语言包含景别、视角等，常见镜头语言详见提示词词典。氛围词：氛围词是对预期画面氛围的描述，例如“梦幻”、“孤独”、“宏伟”，常见氛围词详见提示词词典。细节修饰：细节修饰是对画面进一步的精细化和优化，以增强图像的细节表现力、丰富度和美感。例如“光源的位置”、“道具搭配”、“环境细节”，“高分辨率”等。 另：文生视频prompt提示词 主体 + 场景 + 运动 主体：主体是视频内容的主要表现对象，可以是人、动物、植物、物品或非物理真实存在的想象物体。场景：场景是主体所处的环境，包含背景、前景，可以是物理存在的真实空间或想象出来的虚构场景。运动：运动包含主体的具体运动和非主体的运动状态，可以是静止、小幅度运动、大幅度运动、局部运动或整体动势。运镜描述： 运镜描述 + 主体（主体描述）+ 场景（场景描述）+ 运动（运动描述）+ 镜头语言 + 氛围词 + 风格化","tags":["prompt"],"categories":["technology"]},{"title":"agent学习","path":"/2025/04/28/agent/","content":"Agent工作逻辑以AutoGPT为例子，记录一下Agent的工作逻辑 1. 什么是像 AutoGPT 这样的 Agent 框架？它们是高级自动化系统，基本逻辑是： 不是简单「单轮提问-回答」 而是根据任务自己制定计划，分步行动，多轮决策，直到任务完成。普通的大模型是通过一轮轮的问答来实现最终的任务的但是创建一个合适的Agent可以实现自己想目标，自己想策略，自己执行，自己检查。 2. AutoGPT类 Agent 的运行框架核心步骤 它们基本遵循下面这个 循环逻辑： (1) 接收目标用户给一个高层目标，比如：- 写一份关于人工智能历史的详细报告，并生成成 Word 文档。 (2) 自主规划Agent自己思考出**计划 (Plan)**，比如：- 查询人工智能历史资料- 按时间线整理事件- 写成条理清晰的段落- 格式化成Word文档 (3) 行动(Action)Agent根据计划，开始一步步执行：- 调用搜索引擎 API- 分析网页内容- 写文档- 保存文件每一步都是自己调用工具、处理结果！(4) 观察(Observation)每次行动后，会自己**检查行动结果**：- 成功了？继续下一步- 失败了？重新想方法- 信息不够？再去找资料(5) 决策(Thinking)根据观察结果，决定：- 修改计划- 补充信息- 结束任务**这就是所谓的：自主决策、自主行动循环。** 3. 它们内部通常包括哪些模块？ 模块 功能 Memory（记忆） 记录任务过程，避免忘记之前做过什么 Planning（规划） 自动分解任务成小步骤 Tools（工具链） 能用的外部接口（如Web搜索、文件系统、数据库等） Reasoning（推理） 分析当前状况，决定下一步怎么做 Critic（自我评估） 检查结果，判断是否需要修正 4. 模型的参数设置 Temparature简单来说，temperature 的参数值越小，模型就会返回越确定的一个结果。如果调高该参数值，大语言模型可能会返回更随机的结果，也就是说这可能会带来更多样化或更具创造性的产出。（调小temperature）实质上，你是在增加其他可能的 token 的权重。在实际应用方面，对于质量保障（QA）等任务，我们可以设置更低的 temperature 值，以促使模型基于事实返回更真实和简洁的结果。 对于诗歌生成或其他创造性任务，适度地调高 temperature 参数值可能会更好。 top_p 同样，使用 top_p（与 temperature 一起称为核采样（nucleus sampling）的技术），可以用来控制模型返回结果的确定性。如果你需要准确和事实的答案，就把参数值调低。如果你在寻找更多样化的响应，可以将其值调高点。 使用Top P意味着只有词元集合（tokens）中包含top_p概率质量的才会被考虑用于响应，因此较低的top_p值会选择最有信心的响应。这意味着较高的top_p值将使模型考虑更多可能的词语，包括不太可能的词语，从而导致更多样化的输出。 一般建议是改变 Temperature 和 Top P 其中一个参数就行，不用两个都调整。 MAX Length您可以通过调整 max length 来控制大模型生成的 token 数。指定 Max Length 有助于防止大模型生成冗长或不相关的响应并控制成本。 stop sequence这同样是一种控制模型响应长度和结构的另外一种方法 Frequency Penalty是对下一个生成的token进行惩罚，控制重复数量。 Presence Penaltypresence penalty 也是对重复的 token 施加惩罚，但与 frequency penalty 不同的是，惩罚对于所有重复 token 都是相同的。出现两次的 token 和出现 10 次的 token 会受到相同的惩罚。 此设置可防止模型在响应中过于频繁地生成重复的词。 如果您希望模型生成多样化或创造性的文本，您可以设置更高的 presence penalty，如果您希望模型生成更专注的内容，您可以设置更低的 presence penalty。 5. 具体以 AutoGPT 举例（运行时流程）1. 用户输入：我要了解马斯克的一生2. AutoGPT: - 想一想：需要做哪些事？ - 计划出步骤： ① 搜索马斯克的生平资料 ② 按时间整理重要事件 ③ 生成简要介绍文档3. AutoGPT: - 开始第1步：调用搜索API - 得到网页结果4. AutoGPT: - 第2步：分析网页 - 挑出马斯克生平重要事件5. AutoGPT: - 第3步：组织成文档 - 保存成文本文件6. AutoGPT: - 任务完成，提示用户 这一整套都是 Agent 自己思考-执行的！ 一些典型Agent框架 项目 特点 地址 AutoGPT 早期爆火，超全面，但偏重实验 https://github.com/Torantulino/Auto-GPT BabyAGI 极简Agent，只要几百行代码，便于学习 https://github.com/yoheinakajima/babyagi CrewAI 多Agent协作系统（模拟一个小团队） https://github.com/joaomdmoura/crewAI LangChain Agent LangChain框架内置的Agent模块，商业项目多用 https://docs.langchain.com/docs/modules/","tags":["agent"],"categories":["technology"]},{"title":"先验概率与后验概率","path":"/2025/03/28/先验概率与后验概率/","content":"贝叶斯公式P(A|B) P(AB)P(B) {P(AB)P(A)}*P(A)P(B) 先验概率与后验概率的概念理解在区分先验概率和后验概率的时候，首先的任务是确定结果与因素。确定之后就像概率论所学，由因推果为先验概率，由果推因为后验概率。在上面的公式中，假设B为结果A为因素，那么我们在上式就完成了先验概率到后验概率的转换。 与粒子滤波的联系在粒子滤波中我们将位姿的估计转换为了求解一个联合后验概率，为了求解这个联合后验概率，通过使用CK方程将它拆解成了各个时刻的状态乘积，并求解了在已知控制输入与传感器观测值的状态先验概率，即为预测。接下来利用下一个时刻得到的传感器输入融合这个时刻的位姿和环境特征来修正先验概率，即为更新。","tags":["SLAM"],"categories":["technology"]},{"title":"标定","path":"/2025/03/20/标定/","content":"手眼标定分为两种情况，眼在手外与眼在手上手眼标定的目标是获得相机坐标系到机器人的基坐标系变换矩阵 对于基矩阵到摄像头矩阵，首先选取标定板的三个基向量拼接成为R矩阵。然后以标定板原点的坐标为t。最后为了防止标定板的xy向量不正交，最好在xz方向重新叉乘得到新的y向量，以此提升精度在选取标定板基向量时选取较远的起点与中点较为准确 将标定板放置在机械臂的末端法兰上，而这个矩阵是较为难以估计的，想办法消除左乘基坐标到摄像头矩阵的逆，左乘法兰到基坐标的矩阵的逆多次照相并联立方程","tags":["SLAM"],"categories":["technology"]},{"title":"C++阅读笔记","path":"/2024/04/05/c++/","content":"左值引用 左值引用是一种绑定，在使用时必须进行初始化 引用并非一种对象，而只是为一个已经存在的变量所起的另一种名字（我们把具有存储空间的叫做对象）。因此引用无法再绑定到其他对象。 引用类型的初始值必须是一个对象。不应该是一个值。除了常量引用。 指针 指针本身也是一个对象。与引用类似，也实现了对其他对象的间接访问。 指针一定要初始化 指针类型需要和它所指向的对象严格匹配。但有两种例外：指向常量的指针允许指向一个非常量对象。 指针的值应该为以下四种状态之一 指向一个对象 指向紧邻对象的下一个位置 空指针，即没有指向任何对象 无效指针，即除上述情况的其他值。访问无效指针将发生错误。 某些符号具有多重含义 int i = 42; int r = i; //紧随类型名出现，因此是声明的一部分r是一个引用int *p; //紧随类型名出现，因此是声明的一部分，p是一个指针p = i; //出现在表达式中，是一个取址*p = i; //*出现在表达式中，是一个解引用int r2 = *p; //是声明的一部分，*是解引用 生成空指针的方法 int p1 = nullptr;//int*p1 = 0;可以转换成任意其它类型的指针 int *p2 = 0; int *p3 = NULL; void* 指针是一种特殊的指针类型，可以存放任意对象的地址。 如何检查指针是否指向了一个合法的对象呢？ 检查是否为NULLif (p != NULL) // p 可能是一个有效指针（但不保证） 确保指针指向的是已分配的内存p = malloc(sizeof(int));p = new int;if (p) // new 在分配失败时通常会抛出异常，除非使用 `nothrow` 检查指针是否为悬空指针int *p = (int*)malloc(sizeof(int));free(p); // p 现在是悬空指针if (p) printf(p 不是 NULL，但仍然是无效的！ );//处理方法free(p);p = NULL;//智能指针std::unique_ptrint p = std::make_uniqueint(10); // 自动管理内存 const int i = 42;\tauto j = i;\tconst auto k = i;\tauto *p = i;\tconst auto j2 = i,k2 = i;\tcoutj k *p j2 k2; //42 42 42 42 42 auto与decltype指示符 auto是自动配置声明变量的类型 auto一般会忽略掉顶层const，而底层const会被保留 string 注意在字符串相加时，必须确保“+”两侧至少有一个string类型。，不能直接使用字面值相加。 string中包含了相当多的库函数，使用时可以问问gpt 迭代器 容器的访问有两种方式//下标访问，这里有一行比较巧妙地代码vectorunsigned scores(10,0);unsigned grade;while (cingrade) if(grade=100) ++scores[grade/10]; 但是需要注意的是，我们无法通过下标来实现添加元素。，应该实验push_back; 另外值得注意的是，通过下标访问容器中不存在地元素会导致严重的错误，即缓冲区溢出。 另外一种访问方式是迭代器方法 string s(my name); auto it = s.begin(); *it = toupper(*it); 在这种方式下要注意迭代器与指针的相似性与差异性 数组 数组是一种类似vector的数据结构，但是数组的大小不变，不能够随时向数组内添加元素。 在数组初始化的时候要注意字符数组的特殊，字符串字面值的结尾处还有一个空白字符。 对于复杂数组的理解（类型修饰符从右向左依次绑定）int *ptrs[10];//10个整型变量数组指针int (*Parray)[10] = arr;//指向十个整型变量的数组的指针int (arrRef)[10] = arr;//引用十个整型变量数组int *(arry)[10] = ptrs;//arry是数组的引用，该数组含有10个指针 在使用数组时编译器一般会自动将其替换成为一个指向数组收地址的指针。 运算符 重载运算符不能改变运算对象的个数，运算符的优先级，结合律 当一个对象被用作右值时，用的时对象的值（内容）。当一的对象被用作左值时，用的是对象的身份（在内存中的位置）。 对于逻辑与和逻辑或而言，都是先求左侧对象的值再求右侧对象的值，当且仅当左侧对象无法确定表达式的结果的时候才会继续计算右侧对象int i = 0, j = 0;j = i++; //j = 0,i = 1j = ++i; //j = 2;i = 2cout*p++endl;//输出当前值并指针后移一个单位 static_cast(name); 类型强转 const_cast(name); 常用于去掉变量的const属性 但是强制类型转化干扰了正常的类型检查，所以应该减少使用。 C++11版本的for循环语句for(declaration:expression)//expression所表达的必须是一个序列。例如一个花括号括起来的初始值列表、数组、容器//declaretion需要是一个能转换成该变量的类型。最好使用auto来声明。 statement; 泛型算法 标准库定义了一组泛型算法实现了一些经典算法的公共接口，如排序和搜索，他们可以用于不同类型的元素和多种容器类型。 注意泛型算法并不会改变容器本身的大小，并不能执行容器操作。 常见函数 find（） accumulate() sort() unique()函数可以将重复元素放在末端，并返回一个指向最后一个不重复元素之后的位置。再通过erase函数实现元素的删除。 lamda表达式又称为匿名函数，一般的表达形式为 [capture list](parameter list) -return type {function body} 其中capture list是一个局部变量列表 我们可以忽略列表和返回类型，但是必须永远包含捕获列表和函数体。 迭代器的类型也有很多，包括输出迭代器，输入迭代器，前向迭代器，双向迭代器，随机访问迭代器。 关联容器 关联容器并不支持顺序容器位置相关的操作，也不接受构造函数或者插入操作。 map容器可以用于键值-值的算法。set容器可以用于查找算法。 对于multimap，同样一个键值可以对应不同的值，对于multiset，容器内可以存放重复的值 pair标准库类型，可以用于生成一个键值对，并可以为这个键值对命名 动态内存（堆） 全局对象再程序启动时分配，程序结束时销毁；局部对象第一次使用前分配，函数结束时销毁，static程序启动时在静态存储区分配内存，程序结束时释放内存，析构函数会在程序退出时调用（如果有）。const如果是基础类型（如int、float），且编译器能够确定值，则通常优化为编译期常量，直接替换为字面值，不分配实际内存。如果编译器无法确定值（如引用外部变量），会分配在栈上。如果分配在栈上，则函数调用结束时销毁如果被优化为字面值，不存在分配和销毁的过程。 而对于动态变量我们可以指定他的生存周期，也即我们需要显式的销毁这个对象。 新标准库提供了两种新的智能指针，并且都在memory头文件中。 shared_ptr 允许多个指针指向同一个对象 unique_ptr 单独指针指向对象 weak_ptr 弱引用，指向shared_ptr的对象 最安全的分配使用动态内存的方式时调用make_shared函数shared_ptrint p3= make_sharedint 42; 当指向这个对象的最后一个shared_ptr被销毁的时候，sahred_ptr类会自动销毁这个对象 传递给delete的指针必须要指向动态分布的内厝或者一个空指针，要注意，编译器无法分辨指针指向的是静态还是动态分配的一个对象。 const指针指向的对象同样可以被释放 当我们delete一个指针后指针变为无效了，但是可能指针仍保存着已经被释放了的动态内存的地址，这儿时候我们应该将其赋值为NULL 智能指针需要遵守的规范 不使用相同的内置指针初始化多个智能指针 不delete get（）返回的指针 不使用get（）初始化或者reset（）另一个智能指针 如果使用了get返回的指针，那么最后一个智能指针销毁的时候，对应的指针会无效 使用的指针管理的资源不是new分配的内存，那么应该传递给他一个delete weak_ptr是一种不控制所指向对象生存期的智能指针。他指向一个shared_ptr管理的对象，并且将一个weak_ptr绑定到shared_ptr不会改变shared_ptr的引用次数 要注意动态数组在新版本下的性能往往不如一个容器。并且我们所创建的动态数组往往是数组元素类型的一个指针 面向对象程序设计 面向对象程序设计基于三个基本概念：数据抽象，继承，动态绑定。数据抽象即设计一个类来实现同类数据的存储，可以帮我我们将类的接口与实现相分离；继承可以帮助我们定义一个相似但是并不完全相同的新类；动态绑定是与继承相适应的一个函数形态，是一种多态的函数，通过传入不同的形参来实现绑定不同的派生类。","tags":["C++"],"categories":["technology"]},{"title":"一篇菜谱速记","path":"/2024/02/18/菜谱速记/","content":"虎皮鸡爪所需材料：鸡爪，香料1.首先处理鸡爪的指甲，然后把鸡爪劈半2.油温烧至五成热(150度左右，油略微翻涌)；倒入鸡爪（记住要盖锅盖）。刚下的时候不要翻动成型后分开炸大概5-6分钟，有小泡即可出锅。3.凉水浸泡待鸡爪表面出现大泡，调酱汁：耗油一勺；生抽两勺；老抽一勺；五香粉少许；糖醋黄酒适量4.起锅烧油，倒入葱姜桂皮八角香叶（葱姜后下）。炒出香味后导入鸡爪，酱汁翻炒上色5.倒热水炖至软烂 小炒黄牛肉所需材料：牛肉，香料1.切牛肉（横切牛羊竖切猪）。加入：烧烤料，生抽两勺，老抽一勺，一勺小苏打，适量食用油，适量耗油花椒油2.整个过程中不要加盐，先拌匀香料再油封。腌制一天。3.拍蒜末（多一些），下锅翻炒，不要超过两分钟！出锅。 红烧鸡块所需材料：鸡肉，土豆，粉丝（配菜在加盐时放入）1.备料：干辣椒，蒜，姜。鸡块焯水（冷水），倒黄酒，打浮沫。2.下入一勺豆瓣酱炒出红油，下姜葱，下蒜干辣椒3.炒至香味混合均匀，下鸡块炒至变色。再沿锅边烹生抽老抽，炒至变色。加入八角大料，适量冰糖，热水。4.炖半小时后加适量盐（汤微咸为宜）。再炖半小时出锅。5.出锅后汤汁勾芡，烹少量香油 肉末香菇所需材料：香菇，肉末1.酱汁：两勺生抽，一勺老抽，一勺耗油，适量糖，勾碗芡。香菇焯水，加黄酒，打浮沫。2.加小米辣，葱蒜翻炒，后加肉末，后加香菇。翻炒出汁后加芡汁再翻炒。出锅烹香油 地三鲜所需材料：茄子，土豆，青椒1.茄子土豆切滚刀块，青椒手掰。茄子表面拍粉（可以用塑料袋把茄子和粉装起来然后摇晃塑料袋）2.过油：茄子（三分钟，最好复炸）土豆（五分钟，至表面酥脆）青椒（过油即可）3.酱汁：生抽三勺，耗油两勺，老抽一勺，糖一勺，老抽半勺，勾碗芡。4.加蒜爆香，翻炒出锅。 地三鲜所需材料：茄子，土豆，青椒1.茄子土豆切滚刀块，青椒手掰。茄子表面拍粉（可以用塑料袋把茄子和粉装起来然后摇晃塑料袋）2.过油：茄子（三分钟，最好复炸）土豆（五分钟，至表面酥脆）青椒（过油即可）3.酱汁：生抽三勺，耗油两勺，老抽一勺，糖一勺，老抽半勺，勾碗芡。4.加蒜爆香，翻炒出锅。 五香毛豆所需材料：毛豆，香料1.先用清水和盐搓洗两遍毛豆，减去两头2.冷水下毛豆，加小苏打，盐（不要盖盖烧开5分钟）3.煮好后放入冰水，4.卤水配比：桂皮5克，香叶五片，八角三个，花椒五克，草果三个，干辣椒适量，小茴香五克，葱姜适量。加入盐30克，白糖十克，黄酒一勺，鸡精适量。5.烧开小火十分钟，加毛豆，密封冷藏。 炒蚬子所需材料：花岘1.先用清水，香油，盐，让蚬子吐沙（3小时以上）。凉水下锅焯水，加黄酒，打浮沫。2.豆瓣酱，干辣椒，蒜末翻炒（可放鸡精）3.出锅烹香油 葱爆羊肉所需材料：羊肉，葱1.备料：姜米，蒜末，蒜片，葱（滚刀块，多一些）2.起锅烧油，先放姜爆锅。下羊肉，翻炒至变色，烹陈醋，下黄豆酱油。3.待羊肉出汤后，放蒜末。收汁。放葱，再放蒜片，再烹醋。4.翻炒均匀，出国烹香油 红烧鲤鱼所需材料：鲤鱼，五花肉，香菇等配菜1.处理鱼：去背鳍，喉牙，血线；打花刀（可截两段）。2.起锅烧油，先放葱姜蒜大料桂皮，五花肉。料炸香3.鱼肉拍粉下锅煎（油温七成，即冒青烟）。全程大火4.另起锅加油，煸香菇等配料。5.将24的料放入，加热水，倒入黄酒，酱油，炖至软烂出锅。出锅加盐味定味。6.出锅勾芡少量多次。 咸蛋黄茄子所需材料：咸蛋黄，茄子1.取咸蛋黄磨碎（现用现取！）。茄子去皮切条，拍粉2.油温六成，茄子过油3.放入蒜，干辣椒，翻炒。再加咸蛋黄翻炒（用小火，会立刻起泡），加茄子，加味精4.翻炒出锅，加葱花","tags":["菜谱"],"categories":["life"]},{"title":"周记","path":"/diary/index.html","content":"cbbe6a3acccd59c99d38aeb80053a158d9f251172eea86fbc56d73b32e1ca55d3fdd5cdef5437bf8230db9392b2cca0fb234c340bffc78e6e2367fbd2b99b0a6a4ca232a364c40a28f219e9fbb9c21c77e2a70d6d5110614989c51168d201d5dffb901fd64359fc227a5f2c34941779769fab6e4a93455fde9214a521b7b6b0e95f18d741187ef13a138f1b6ec63c4f585652a9bd938a6c0746e746f9d503ff049b27ce0f73e227513e2ad9e343307edaae6968c707f556486203723f429bdc8ec2ef503c8117c88f23a67c5db2b8e01624761181c9135fe73c2808a42c6045569bebaf4d76a70de7b0c64b7f4e578dece7f88ba9e51288d25bcd5edc60d94083503ecefc1faa4c388013c5d448cf39e371063fd318c2fb28b245fe72cbd8e74033fd7ae61b88457722060a6ef3b06cc9b0ddf2be65a804512b04d12188933a70d112bf4b2505dbef3de57a2cfcb5271ef31655eb9a7569085a8e5d6b2bedaefa03e39dccd34c5aa4ff5a174181587025cf5cb8c015170de42b5529fa82b3ae1125d06eb9d9c66634efda7cedeefcb0467bf36b7a65abe74d659a61b98366062defa04969a9aba23061c02d52bac5f7280eda285697926c2bc94af813cc7c1b1406f7a9ce9f7924650c9d1782fc79291eb7784b0beff01aec649537f8dac65dbc9d5aa739cc1db79f98ae9f340595906bbec213c5cae90e56bde98d009c1839a04128c5497f4fef4909128859d1c7e26808645ca781b2697895fa28d72f0b94c21046d2a7443fbdaabe2f138bf93f8584054e239a0e82e59b247fc9280f28f7f9b2cf55c71564187fba0be5ae47fe0c24f410c2ee331e3c38c3f8169ffa099f7321b821deef4af053105036a3aec2885ccdb7048d536b48f85259e91750fa04c8c51c91fd9c831a810698fbbeae6d1ab6c1793195c510217eb9e7124f0a64899dd2837bf211fa5d237521a3f4aedb391936c6f1e9c21e49297881982b20ad2228b302507fddc52c8c9e4bbc77f1e3808b923324e57f5e9a7fb8871e6d5810d1910628a5e2b9a150afb43739a6c3d251dc9ef3fdb93662a2af0aafe1e9140e59a4f6f63da166f9f95dbebafdf613640f35a88a869b3e493d01b0249bce0e4069624a2771c4c79b76ef7c32e8d95356cd51ee7685706c88e1dd6370d577481a3514fdeb38801d0e2aa3a3c5085373264bde507afef831f4a63b5180360d9ed1818dffc6538f51090899b094c5faa39b5547e71de37678f874ec6dc3df466cca7a01698c29275ba752d5ed6a290892af4e4978df48a70d5068cd5f442553eb1e1ccf20567d3e266c6a9b79d450fa08bccf80f99219eb718f1adc9bd28d24cba02a556e039a2822c69a7bb5961daadc120372773fb45e2308eeb16bd215496474aae4a0dfdba3d7122f89c3abe36b5155a88fc0d18c904e10bd5428eb6ae0f5cd7467e95bc031d2bfa8fa7d48753aa06f50b731a21be4ea4d198b997c693c957a97f0ed1dda01c9c7e946c64c62ef33360821b4cf67368e2df3fc078a7554f519b9c3c018cf75008875249b6955fa29df7dfdd233eca58746ac7369a1bb2042cd50bd0068c00bf82652e6ab3ab1ce5520641d08242845b5665c245a6836e4dbd0e60346756377c93fb871d39a57ccae8e42f7454a5b7c66f44a14d794a45cea75bd836613c9b3c2f67964fd739d2ba8a76207de6cedaf015c48fc55bdff16c4c639d6c6a1c7996d8e38e688b2a2e260ac1f043dabf2f78bd0cecd8e6e9af22c7b7368d012f5315483000e9dcc3c79a0992416cf43b97aef84e4e86af62ff9d4ce14aba4b7451f98b07d627f9f7115a3a1672ca30873e876e5169120acc63226f34497ade28a394a08fe9914c73e38f18116bbf0b8862913b165ef6c6671e58b7f86e07cc600925ad7b56887e6e09cf99c4e98a1268afdb3fe6707660504c7283d8d9e11fa29950c9a82f20c0bcb5f274fdbe57eb80281810738e09bf42231d97e1a8556d8a5350c389909c50e4f087181a1d8143e502a974aa1cc7bcee0ea00ff08a0f48fb2ee39147a75f902058edf12348e2dadfff18667e6af1780e3ab646a4ecb443ac898ef0afae4adfbe0fcecb835577b604a856a0611c4678c472c25d42006c5faea0436d21c240ecbd8b27b5adfbe07c4ec67f090901e56e461f1f1b88254b7f6da2ccf6836fcf932cb9001ad748f876783d24b5b3818e538ff616478cb2ad36aef57bd2be981b03070a8aa2147bae7987d5c0a1ced267529612d9fad852053be989348ec9a989e4ef1b336fde9d1727e194ea215efc9756ea136643ba1a4cae545a59342bbb7ff71b4f446ad6b92f4b729d2a8b74c7323fa9204572542c6448d2bbee52d0de95cf92d130800bca8ddc2ddface12c235ed31a553dc1cb1764085586de4d70d2eb1358b3b77eace48cb7beffdeff00d9c628584e310501b9a07a95ad40b193d3aaf55ed28d68d710891c6dd955a1a79be06f1d5c4b4b772bf763ba291dfe5420de75984f318c93fe49ac8f21292f96293bac1c44a9261813231bf04f785d8a21d9945e812bee6f43407bc418f0430a82c42246cabc12b37c1f4b2ed76adb8c34b46df499c0ff87f65b43d70937f33e83ed1cdc8e7d24d6a276e12f0c9d389dc717fc9490b7d45cfd43db082a5b366dfa2686f85df4b0afcd32402a5e0259b57c832b86e134814c2196859ea19bc9fe00ef3b27bf18d22f3a255e399d9709abc257ac3861facb5f7e6b2ab1babb3f43406ad1121aec6ef32f6b07a2f03c56c3bb25ab6b7cacb1a4e48f1e77f5316f8e2da41cd26aecbaf039a6cf5bb77db019461fa4d47d5d4936f0ca1b7f15dc4ee71ff9b1e670a4ecc37ba26b3f19b155012fe1ec105fcf82401c2a79a4080fecedd95c2fff7749aeadddccedf6b2a8bd00ca5168db4cc658d77e048d400617ce9c1a794c2df9dafb4442bd3295119d93d8439da2647e4e421feeae740f60f16e34cc01e9e4c5d5baba6a3978bc2e07fb0a3f5e7de862d43ffcd8e4be456d15d82386a085156277a3c8e576c4f59261f8e6bd26a0ca696d1f85ec0e1dae026a053f70d013a7e28331858ec32a651966c1323add5798f68c66fdb40581067a76302bc6a99a36e04c4ee092e9291212c4ecf5b9be3dfb4eb03da6491d606beda59c615523a5b7d34122891ad65d1ea20440c232c56d6cfd499ab7b87b95796ee6af347256795b62d02cc1ca5b043fdb1aaf52d681952d9a25517028121039a2b94e44731d98292fd5f5d6d22e5fd04e34b90138411a7bc85dc587e21b6c0164042cbf2e56bbb8329a7f7d4821ce5fedf84b2d4d2d5d6e90f8c7315097c9f5539b63a280fa3c0a6fbb55259a3c2bfe4dcb55f2919ce64df37b75259b0a74f3340d746d839e1b0d8dfef71da1064ba5a67bb737f259efa3f2010166990fead600d18535a2e2beab7f9717e92771d451de481a7725e4b62e5ba828d29cbf81ab9c45954ac2b28e31afdd63f6f0500ca6125e41cdae956badeddc7f79094bcdc3744dc832dbc8feb2bd459324a5c3866ce3a81734d0f260a136b7940987921db2fabe93af81a49147e416c93339257111d1e43c6716e1b35639f1320099067b86e19b6f8b03e9afc8e33968b00635ba78cdba69ecf37fbff32d29acfd8b39b7d108440634b9ebb462d59bbbf43c7fac5a2fab0a456a2cf9fdc4e37f4c7d2808abbbfb262809315a5d4791c1999af9543e027fdb0900d068f2b85689f4ed0c4814ce80bf26e05981d09f43d279d2547cc65a0989215811d1dcf9528c8f1d1d6699d0d2173375fc89eb9bc6ec661c3f7eb0777cf13f46d10ee12afe86438e2bca3adaeef6a3b321893935748acafb3bdbe819a9ae02249a4c39ac34adf0c1c1cfbc7ce18a2a98a5f5bedfc9ede7fc11af6486e1998a213be362ea96c556560c7c4ed54d09ed464950c5c170f7ae5c604676bdf0863bd17da542b4939599b550d5a505745240e08e6e04b0deb538922f3df040fbbe8bf827da8bee4313aacfe59dadc4ed6a7ddb817a814115a4ea20534879e7bf6b22991ea67ad3d8c0d383021734cfb8a664235386c3c0eb54625284de9f193d74b438cf080ff1d93459119961b29d9331a27381842eb3d6d6fc0d6d1c5b8ab3aad2572dcbd63085561c82a7f7d489b2484760be74056033c600bc1218963d9be8e1ad7857524f2d285c11d98fd6d3ebb8b3b49528b68775357a4d44813d0428c5efd0c3aa58988ca4eda5e85a6157ba2af8db4f32cfb8913bc8a962de5b7109a7b4e3aa545fca849637086d59962f7bce66f7adca7e2bd5629e6fcd7582dc97a8febb046c381fa53de403a3bff68ab43fa81a1bea617faeaade02ec40ff9b5003813e8c9b9e1dd5e625d94a3c4209836d5ec06ea939c70bf19073c75b60d87b97cc7aab58c27d04816d5029ab2403b63b9ec6838bf68022753a2400fa59e5d8888764c8b14b81c405c19075cbb7c1dac545a636d1bef0ede6f3dd421daf19b252b03bdada9e97a89e3b5d0415259404b874aa08c54b6b57249a67a7f80c683f18339a3f0fdf584ddb5224024205fb60afd77203ec2891983365a392b6b65e9630435eba5e41c20840be068dd3548b81afd4205dc2909c6bef26f663576a9561006ff9fa719ddcb3fba2df89664ded7439b11cbfe7d23c87c923bde4604ac082873cdf4f72daf290e46bbd628be26c8eb51fe2f19361b4812656c01965b39585fc5a6b354aeb0c1a4720b96ac1a7f5f46bd95b1b3eacb6c839698c0a91e7a5a8eea5af85411e01dd92282a0ebf87f3cdabfa96b147fc4128346f7c74f86c9caef534ae78f3a95724f7b78fb856b471b8feb9d5dd0756cd1c5f1864bba41b075ff7a0e0adae76d948621dd0b2913db82252a3b8671f54186732ec37c6e287dab21798d31601d3a60489a524e73155dd6b0751a4bd248266127868ec7140508a2afe2ac76d4bf270f0970676b68c67588396a1441ffd87a0b0d8898895788003322fc5ccdd2ee73ce854a21f31e3efe7a0421fbb85679e933a94762f71e0bf0664e0ce87c3854dbb32bfa4710cf082130515fb05f81ce1c22b0c78db610251e95535d584b376566c0dba7eb9d361f35c4dbcc38986cd19b417884ba18b0e988afc570fab39043c788981d89c38e898d23c4d518c131de9a6dbc0e7f9b162f61011b586aaa34f48c01c49dabe9dd162a9c41a80efa60554a495642a2c7b3279fb7d340c425de5163665c934ddfa69af8ccb1ab25bb9b77b2814b7b2d29f3a31d15e69ea829be978abda2e67a6a1c6b5ecf7783a6b17060e1c2d4e1c33f44a4c3f9b1936d1644e0be958485a95d0aa74b4d3198eb1b8bc2300e68e784156ac44581886103177e5e714f3a00f40608d724e43a0975f1a485e5e6f2371fcec89557aefa03b8f6141068c10c35225a63310ece510605bb26a8d7ce6ad406867462e7057a60aee143affe9b7b83fc141be5f02459c5842622feede047accc2b78862968b0a2f237a1a20affbe3235054418b1fbd07d27010c3d6e0e49d5166d0bfc078294277858c943e65cdb10af81fb2b1e17b1365d2f51b9a6a8ebacb88ef1c1e8f0f1e01562895ade0a137c4fccc0ab3b410cd3c90a3a69bfda46a0db8e559a4b527b24bca0e9abe1d7658560e52701ec2b9bd879213c3e2bd5b2603795930bbdef686e28f0b879f1a17f6b399381b87b1ec08a7527c8903e58024649dcdb4f4a13f498bd686befb82a95448e1f44f854983ccb80658338c0b74ebfda6683dd876031a999abddcda904b8621924d2410b058fbb7401683a96d9c8ac2de1dabe00c634077bbe48e28614f4857067ffd242f5ef7bd90b6a7c86ff8224458c3f708702bdc0dcbc637610c8f38674eaf59eecfbd267a8ad892801bbe03bf5f70a1fe9c9bed7792912edbccc6938e26de85c3b6d68da20bf7f7e63164da4888a304e8678d8dde7399d981ab2618b8614a14cdd3b20d69f38b83a56f878b713c3f03bc2a300e7861df53023e9c4f3f33cbd399090d294163e2fbaf5e7d6c22a8a40bad282e691743a7c7dfb999218c6894c997f1bd0a09b612f11cfcb85501d86970b78fc705fff9559172f532fc260fa2d17ee465c277de72b3d8e3e27e1ccb1ac04ed1cbe7ab7d7a7679554eb76e47b47e5a863bcbfda91bf544d0ebee471c869e7dd334fb11fe3e127f4db6afb895b16295e02d2e624b3545b0e4e2361f0e83f0c986d1ff7b816d82bcb6ed5d0efd65844a958691771c242bb82dcc82fcae1ab1fcd43ca9e5aceb23333b6585663c77e70b1d66abffaa9a7de718062ea4ccf7cd03fc38f4145e1e04eb37114ec85a9c688f1d5a0e1d37f3b3da3a24c0dc6ccdbcf80df257ac27ed9f568c567af36643df39c51c2aa327b945ca5ab135cf39047924bab0762ebbfcdcfcb404654e53fe0d52163b6cf0323ec3a4ce1e9a3ec98aa00c5806bdbadfde1cce2d44b4ca6c18384ce495499c7a09e73c50b6e66c64ed6057054ee2fbb606068b29c87d91588223f44fc559431f275e69ac8f328ae7fbf06934492af7e1056f16bfda541ad8e1be249fded87ed5d39b82a39709844e6fe2088dd9a2f50f7d3c9ba6b16e6029474f96f59fea1337b160cd8b9932b0993058e9fff0400e55be8737797c77f0900f2465bfa934697d2f17e3d2f769fc744f928b4a326191bccab6c906e37bf7aa8e6ddbdad2631de3acf9bc7fd4fb5d35f6eed8f1553f5a7a6853ce433f34ba8fb6b8d9bc3b27b50087d31f044f4ee79dba99f467911cfdc65611a3c366c40e4656d934ee729aab6acdbbeba0e93a7e25b94ddcf6666ba7f1a51b1d3348fd4c6df0d7aabf8e3fd7f558bde1cdd48de36d9bc3693a3a2f2c8885b08d8a691c7a0cc2e799ce971986b89c2341499e80ae5b9fa69d0527ff96d4bfcda96c44dfa07fdd04cebcf995be374298718f34dd75f1ce723b2cd1f5a37b2c3f118999becc8eda40876f1edd89444110d08edc35dcb0de798c852f431641e1770009effa5c8495a058c43df4c3026368357de9724f768e69e120249249fd2907ab8f618cb174d609d51790bf36138db4af95bcd8b8372b62179cd54b71b32bb06cf14f48b42209fdfa98722b11ae46e73d844c5750280c46814c71baf4d86e0a5a4d41a1655823b0d82f359fb48a39ced85e0fcbdc7333bfc58ca7e2f55583fe7576ae927005418bad056c0974e7921dec4fece90e25c1c7c4778c19ab0329d2b18fa52ecff8ebb48d9789c1e1ab28caa5b7844e8b7cacfaccb4ca4871fc3afdf58553a57c4f7c7e8227581e8e5f000394d1c31ca22e08b2107144cd763bf895dd9e63450700adaeec3cb299a2ed7a819b0e1df3bdb41817c253833ce742894133618b443344927883b0b239bea06e36b99240d70329a90cbb0a4be8d120d5868b8878559cb4cda63e19f4cdeec39a4f02d887846d237981e4b60c406da807924b481e40614091c0c9c142fb50f0518d885e6024ef748148a31089916677af7d68affc72d8632cced390e1eba65b4a321ece30b88f14cb87df711d4ce2be832ce13b5b060c9558f0e03c0921904edfbeb10920d2bfdc9547d8d61265ca6d04640ddf7d051dc041e8ae5898856a21edd7d73f37bf6c75ec9c0cdc89143e1ef1b6a198cb5fffa347d57ada13bfe6510cdff23d9ef9007939025f5b9855e81d902f0282fcceefa5dc45545dbcd01c8cfeb5ca2efb58bbf4924bdced65f4ce23b5ae557413fd3bb0ec11485627e4f78c257e16f2cee10baf47a1d4e3f8c508eb7ddee993fd7a703f17efc08494b19fe2d38ab2f8ffa13623cd09a97f45bdeaa608a8e14e2f26cff7731eb194de09cdd416935bf11bac94fb4e99d15d18517d010e352a8ee9c5b081ea1213178ac49ecd05e9a3fc3dab2a5fb58d4052319ea1bb0dceb565508e19424db1b7bba313520c10c6add7d1a8945e2365105fecd41e412a0cf0216158295a383f340626b39a0ce871161b8205a528ee8db2907de348569c9e9b30b8f08a7f2e6087d5d90e267d875ad948845dea9441bf8df21fd193e0da782dac01e63ee5e55e9c8b4dcb3fcd84a5cb4b76439d487e70a2b1b64ac1e2a9e6bcebba0bf03e3344c142d7aa731bf5d3cd6d2b287d6c3945cd00cceb2c5ede0d5542e245377b3f4acf1904dced09fc13e90bd2642f512347f22141c10e67c9b26991109e443538b04e21a4c0269f37f498047d7fb0559b4f09044be01a129716dfa2e5a892ce122aa85d94eeb0d1c82ceed6e86e7891a53bdd03f92bb99f43c0a2dfa5db8d1c8766f7c95ceccf67f8b030f0d8f3d4a32c35e05b9095feb6e0eabf1e288b7ad234cb646fff2f74ab397bbb834ec55e0945e5f2922ddd48807cf6600a5565d63d76ff70a77cf7ba4cf000a3365be37280a18419771835fd639863212c20f415670b2eb05e6a4a836f8d42766488556034256664dcd0e7190f987fc47591a7b65fd2e32b157264bcfd0bd14e263eb3c89515406f6d03a801e05998db9ca6db006280fe9e64150fabba509cd2f21c7c2cfcb52e33f802b1849112cbf25b8512b55eb7838a54ba1943b966a4a11f3b299a61361093300a1ddf19f1e8014563a3e23f577d7acb6e039ab555bc3a9649c4aaa81406072229276dfaa86f26ed871ff0698be0ce4f6768789c86f25e05a39a92d007fa78ee8327013d05462718f1c246dc9af5178e2eecac0ba7a0ef66885a1f5ce1aadc900d9cca56b5275839d860fd6e6fd3b0e66c9ebece09f03a8196d6b5f5c685138716a2cef9bae0c6be59b0e4766271358f43a85ffdd8774d75ec4ff31e880d6b8dbdaedec4b7cb69a02eca17d3c8e3ec140dc232038cfff65240d200dc408b4c0ccd760e5e5b90de32bdc2f07131a043ecc8777c25e4bc30f7450bf8fdd0c7efa6cd505c86590650cd126690cd9bd7e1277463baedc38ad3b9907127b844167090f58714f03570eaee16ccaa53c17aceff816a8549be5aadf232d53fa148d966bb978887b04cf68b06feb62f64cbf1c57aa1e1b159cb4b1cdfe08b81f28d0c9891de49d9c4208f930d3b8bb8fd09f4a2e5ce82db5e5267f314c4e16921a4ad87468f654e65471330687511e7f34147fd5738ddfa370ab1bbee4dbaaaef291c4fdc2430281a4ca85734ebcc816a98542e1db869c1d0a099bce7bd3a34deca823dbd1b9a54b2740b8946a2e9935debbbbb9c3e7db65d69402601783689a5139531c0c8632b246a6e3e46a510f3998c8a757398d649d4ea8439872b3601e05368238ccf1a9f504578ea52b668ff9a00f4086a00002e6a5c905b771369f3f192c75a1e6f7ab3cd359de95e7f7e15da52726a556c34c68adb9f14601e180c98afdea894a6f30b76928bebdb8a4a65612d626a35c52043d91482cb55c547073dfac8f126ab0773288e5fb00ed83db1b610b2150914ee3e5fd2a579c5f0b52750085cea6327483d966e48c3e8097d9bf05609f18933f3ee0410df6ce52972f376a1a32a3e4d4f28bdd48509fdbd579bf0824b478a254b3acb8d6c9952f1a944e1d50568c5047a9ee3738ef3350073547969abb630a5ff557d1cfaa6dcc4bac43b996f55e19011bbaaa3287be34d109ec0332154205618a6df38d70405072a13896176b350cb19c282a26cc40b207ff7c8ab259327588d7433b016e05afe60dcd4b32591c3724d9e5557e5c1a34a2dbfcf 总结你的进步吧！"}]